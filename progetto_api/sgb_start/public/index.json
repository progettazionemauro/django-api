[{"content":"","permalink":"https://example.org/django_retrieve/django_retrieve/","summary":"","title":"My Vue Content"},{"content":"","permalink":"https://example.org/vue_retrieve/vue_retrieve/","summary":"","title":"My Vue Content"},{"content":"Welcome to StackEdit! Ultimo aggiornamento 21/5/24 - h. 17:47 Hi! I\u0026rsquo;m your first Markdown file in StackEdit. If you want to learn about StackEdit, you can read me. If you want to play with Markdown, you can edit me. Once you have finished with me, you can create new files by opening the file explorer on the left corner of the navigation bar.\nFiles StackEdit stores your files in your browser, which means all your files are automatically saved locally and are accessible offline!\nCreate files and folders The file explorer is accessible using the button in left corner of the navigation bar. You can create a new file by clicking the New file button in the file explorer. You can also create folders by clicking the New folder button.\nSwitch to another file All your files and folders are presented as a tree in the file explorer. You can switch from one to another by clicking a file in the tree.\nRename a file You can rename the current file by clicking the file name in the navigation bar or by clicking the Rename button in the file explorer.\nDelete a file You can delete the current file by clicking the Remove button in the file explorer. The file will be moved into the Trash folder and automatically deleted after 7 days of inactivity.\nExport a file You can export the current file by clicking Export to disk in the menu. You can choose to export the file as plain Markdown, as HTML using a Handlebars template or as a PDF.\nSynchronization Synchronization is one of the biggest features of StackEdit. It enables you to synchronize any file in your workspace with other files stored in your Google Drive, your Dropbox and your GitHub accounts. This allows you to keep writing on other devices, collaborate with people you share the file with, integrate easily into your workflow\u0026hellip; The synchronization mechanism takes place every minute in the background, downloading, merging, and uploading file modifications.\nThere are two types of synchronization and they can complement each other:\nThe workspace synchronization will sync all your files, folders and settings automatically. This will allow you to fetch your workspace on any other device.\nTo start syncing your workspace, just sign in with Google in the menu.\nThe file synchronization will keep one file of the workspace synced with one or multiple files in Google Drive, Dropbox or GitHub.\nBefore starting to sync files, you must link an account in the Synchronize sub-menu.\nOpen a file You can open a file from Google Drive, Dropbox or GitHub by opening the Synchronize sub-menu and clicking Open from. Once opened in the workspace, any modification in the file will be automatically synced.\nSave a file You can save any file of the workspace to Google Drive, Dropbox or GitHub by opening the Synchronize sub-menu and clicking Save on. Even if a file in the workspace is already synced, you can save it to another location. StackEdit can sync one file with multiple locations and accounts.\nSynchronize a file Once your file is linked to a synchronized location, StackEdit will periodically synchronize it by downloading/uploading any modification. A merge will be performed if necessary and conflicts will be resolved.\nIf you just have modified your file and you want to force syncing, click the Synchronize now button in the navigation bar.\nNote: The Synchronize now button is disabled if you have no file to synchronize.\nManage file synchronization Since one file can be synced with multiple locations, you can list and manage synchronized locations by clicking File synchronization in the Synchronize sub-menu. This allows you to list and remove synchronized locations that are linked to your file.\nPublication Publishing in StackEdit makes it simple for you to publish online your files. Once you\u0026rsquo;re happy with a file, you can publish it to different hosting platforms like Blogger, Dropbox, Gist, GitHub, Google Drive, WordPress and Zendesk. With Handlebars templates, you have full control over what you export.\nBefore starting to publish, you must link an account in the Publish sub-menu.\nPublish a File You can publish your file by opening the Publish sub-menu and by clicking Publish to. For some locations, you can choose between the following formats:\nMarkdown: publish the Markdown text on a website that can interpret it (GitHub for instance), HTML: publish the file converted to HTML via a Handlebars template (on a blog for example). Update a publication After publishing, StackEdit keeps your file linked to that publication which makes it easy for you to re-publish it. Once you have modified your file and you want to update your publication, click on the Publish now button in the navigation bar.\nNote: The Publish now button is disabled if your file has not been published yet.\nManage file publication Since one file can be published to multiple locations, you can list and manage publish locations by clicking File publication in the Publish sub-menu. This allows you to list and remove publication locations that are linked to your file.\nMarkdown extensions StackEdit extends the standard Markdown syntax by adding extra Markdown extensions, providing you with some nice features.\nProTip: You can disable any Markdown extension in the File properties dialog.\nSmartyPants SmartyPants converts ASCII punctuation characters into \u0026ldquo;smart\u0026rdquo; typographic punctuation HTML entities. For example:\nASCII HTML Single backticks 'Isn't this fun?' \u0026lsquo;Isn\u0026rsquo;t this fun?\u0026rsquo; Quotes \u0026quot;Isn't this fun?\u0026quot; \u0026ldquo;Isn\u0026rsquo;t this fun?\u0026rdquo; Dashes -- is en-dash, --- is em-dash \u0026ndash; is en-dash, \u0026mdash; is em-dash KaTeX You can render LaTeX mathematical expressions using KaTeX:\nThe Gamma function satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral\n$$ \\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt,. $$\nYou can find more information about LaTeX mathematical expressions here.\nUML diagrams You can render UML diagrams using Mermaid. For example, this will produce a sequence diagram:\nsequenceDiagram Alice -\u0026gt;\u0026gt; Bob: Hello Bob, how are you? Bob--\u0026gt;\u0026gt;John: How about you John? Bob--x Alice: I am good thanks! Bob-x John: I am good thanks! Note right of John: Bob thinks a long\u0026lt;br/\u0026gt;long time, so long\u0026lt;br/\u0026gt;that the text does\u0026lt;br/\u0026gt;not fit on a row. Bob--\u0026gt;Alice: Checking with John... Alice-\u0026gt;John: Yes... John, how are you? And this will produce a flow chart:\ngraph LR A[Square Rect] -- Link text --\u0026gt; B((Circle)) A --\u0026gt; C(Round Rect) B --\u0026gt; D{Rhombus} C --\u0026gt; D ```[toc] # MARKUP HINTS By Mauro alle h. 06 12 maggio 24 I have my README.md inside my project. Here are a method to work with your README.md separately while working on your vsc local project: Use an external Markdown editor like [Typora]: (https://typora.io/#feature) ** (a minimal markdown editor and reader) **. These editors provide a live preview feature by default. # BASH - trovare la oporta occupata: - `lsof -i :8000` - chiudere la porta occupata forzatamente: - `kill -9 32394(esempio)` - vedere i comandi che iniziano per una determinata strina effettuati in precedenza: - `history | grep \u0026#34;kill (esempio)\u0026#34;` - trovare la porta occupata: - `lsof -i :8000` - chiudere la porta occupata forzatamente: - `kill -9 32394(esempio)` - vedere i comandi che iniziano per una determinata strina effettuati in precedenza: - `history | grep \u0026#34;kill (esempio)\u0026#34;` - Azione Bash - Quello che segue è uno script molto importante che permette nell\u0026#39;ordine di 1) verificare se la porta 8000 (che viene utilizzata normalmente in fase di sviluppo) è occupata ed eventualmente chiuderla; 2) aprire Django 3) aprire hugo. Al momento sono presenti due file separati per una migliore comprensione: ```bash - check_ports.sh \\#!/bin/bash \\# Check if any process is listening on port 8000 if lsof -i :8000 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1; then ​ echo \u0026#34;Port 8000 is in use.\u0026#34; ​ \\# Get the PID of the process using port 8000 ​ pid=$(lsof -ti :8000) ​ \\# Kill the process ​ echo \u0026#34;Killing process with PID $pid\u0026#34; ​ kill -9 \u0026#34;$pid\u0026#34; ​ echo \u0026#34;Process killed.\u0026#34; else ​ echo \u0026#34;Port 8000 is not in use.\u0026#34; fi run_project.sh #!/bin/bash # Navigate to the Django project directory and run the server # cd /progetto_api python3 manage.py runserver \u0026amp; # Navigate to the Hugo project directory and run the server cd ./sgb_start/ hugo server -D Per cui lo script generare APRIRE I DUE PROGRAMMI DJANGO E HUGO è il seguente (ADA PERFEZIONARE!!):\n#!/bin/bash # Check if any process is listening on port 8000 if lsof -i :8000 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1; then echo \u0026#34;Port 8000 is in use.\u0026#34; # Get the PID of the process using port 8000 pid=$(lsof -ti :8000) # Kill the process echo \u0026#34;Killing process with PID $pid\u0026#34; kill -9 \u0026#34;$pid\u0026#34; echo \u0026#34;Process killed.\u0026#34; else echo \u0026#34;Port 8000 is not in use.\u0026#34; fi # Navigate to the Django project directory and run the server # cd /progetto_api python3 manage.py runserver \u0026amp; # Navigate to the Hugo project directory and run the server cd ./sgb_start/ hugo server -D Mentre il codice per chiudere i due programmi DJANGO e HUGO è il seguente (da perfezionare)!!!:\n# Find Django PID and send SIGTERM signal django_pid=$(pidof python) \u0026amp;\u0026amp; kill \u0026#34;$django_pid\u0026#34; \u0026amp;\u0026amp; echo \u0026#34;Django process terminated\u0026#34; # Find Hugo PID and send SIGTERM signal hugo_pid=$(pidof hugo) \u0026amp;\u0026amp; kill \u0026#34;$hugo_pid\u0026#34; \u0026amp;\u0026amp; echo \u0026#34;Hugo process terminated\u0026#34; ps aux | grep \u0026#34;python manage.py runserver\u0026#34;; reset GIT \u0026amp; GITHUB Riferimenti Mastering MarkDown\nRicordarsi di aggiungere .gitgnore - git add .gitignore - git commit -m \u0026ldquo;Add .gitignore to exclude compiled Python files\u0026rdquo;\nPer effettuare il push da origine a remoto - git push origin implementazione-pagina\nSwitch to the New Branch: - git checkout new-branch-name\nCreare una nuova branch e posizionarsi sulla stessa git checkout -b new-branch-name (Il comando può essere visto come la sintesi dei due seguenti comandi:) - git branch new-branch-name # Create a new branch - git checkout new-branch-name # Switch to the new branch\nYou\u0026rsquo;ve created a new branch (template-tutorial) without committing changes on your existing branch (implementazione-pagina) To address this, you\u0026rsquo;ll need to follow these steps to commit your changes on the implementazione-pagina branch and then switch back to the template-tutorial branch. Here\u0026rsquo;s a step-by-step guide:\nCommit Changes on implementazione-pagina: Assuming you are currently on the template-tutorial branch, ** switch back to the implementazione-pagina branch:** git checkout implementazione-pagina\nNow, add and commit your changes:\ngit add . git commit -m \u0026quot;Your commit message here\u0026quot;\nPush Changes to Remote (implementazione-pagina): Assuming the remote branch is named implementazione-pagina: git push origin implementazione-pagina\n** Switch Back to template-tutorial:** Now, switch back to the template-tutorial branch: git checkout template-tutorial\nIf you haven\u0026rsquo;t pushed the template-tutorial branch yet, you can push it to the remote repository when you\u0026rsquo;re ready:\ngit push origin template-tutorial\nHow can see from my vsc local if a git branch is present also in the remote github?\ngit fetch --all git branch -a This fetches all branches from the remote repository and lists both local and remote branches. Remote branches are prefixed with \u0026ldquo;remotes/origin/\u0026rdquo;. Check if your branch is listed among the remotes.\nCome posso creare una nuova branch in local, e poi crearla anche in Github, poi effettuare il push e rendere questa branch principale?\nCreate a new branch locally and switch to it (chimiamo la nuova branch template-tutorial): git checkout -b template-tutorial\nPush the new branch to GitHub:\ngit push origin template-tutorial\nSet the upstream for the new branch:\ngit branch --set-upstream-to=origin/template-tutorial template-tutorial![alt]( \u0026lsquo;{\u0026ldquo;class\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;title\u0026rdquo;: \u0026ldquo;\u0026rdquo;}\u0026rsquo;)\nNow, further pushes can be simplified to:\ngit push\nTo revert the changes and go back to the original commit before the changes, you can use the following commands: git reset --hard HEAD git clean -fd\nThe first command (git reset \u0026ndash;hard HEAD) resets your branch to the latest commit, discarding changes. The second command (git clean -fd) removes untracked files and directories. Use them with caution, as they are not reversible.\n-fd stands for what? In the context of the git clean command:\n-f stands for force. -d stands for directory. Together, -fd means force removal of untracked directories. This option is used to remove untracked files and directories forcefully.\ndelete a local branch and also delete it on the remote repository on GitHub Delete the local branch:\ngit branch -d branch_name![alt]( \u0026lsquo;{\u0026ldquo;class\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;title\u0026rdquo;: \u0026ldquo;\u0026rdquo;}\u0026rsquo;)\nReplace branch_name with the name of the branch you want to delete.\nIf the branch contains unmerged changes, you might need to force delete it:\ngit branch -D branch_name\nDelete the remote branch:\ngit push origin --delete branch_name\nThis will delete the branch on the remote repository (GitHub).\nUpdate your local repository to reflect the changes on the remote:\ngit fetch --prune\nThe \u0026ndash;prune flag removes any remote tracking branches that no longer exist on the remote.\nI want to synch another an oldest branch named \u0026ldquo;template-tutorial\u0026rdquo; with a newest branch named template-sheetlike and after delete this last one (template-sheetlike) Switch to the template-tutorial branch: git switch template-tutorial\nRebase template-sheetlike onto template-tutorial: git rebase template-sheetlike\nPush the changes to the remote repository: git push origin template-tutorial --force Note: Force-pushing after a rebase rewrites the commit history. Use it with caution, especially if the branch has already been shared with others\nDelete the template-sheetlike branch: git branch -d template-sheetlike git push origin --delete template-sheetlike\nAutomate the copy of a file from a repo to another when pushing the commit So let\u0026rsquo;s say that i have cheatsheet.md that i update regularly as it would be a wiki page. This file with the same name is present on different local repo. Let\u0026rsquo;s say that i am working into my local repo named /home/mauro/Scrivania/dJANGO_apI/progetto_api/cheatsheet.md.md. When I do a commit adn after a push into github repo https://github.com/progettazionemauro/django-api I want automatically copy this file and update the commit also into my https://github.com/progettazionemauro/wiki-wag How can do that automatically?\nTo automatically copy and update the cheatsheet.md file in another GitHub repository whenever you push changes to the first repository, you can use GitHub Actions. GitHub Actions allows you to define workflows that run in response to various events, such as pushing to a repository. Here\u0026rsquo;s a simple example:\nTheory Create a GitHub Actions Workflow: In your Django API repository (https://github.com/progettazionemauro/django-api), create a directory named .github/workflows if it doesn\u0026rsquo;t already exist.\nInside this directory, create a file named, for example, sync_cheatsheet.yml with the following content:\nname: Sync Cheatsheet on: push: branches: - main jobs: sync: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Copy cheatsheet to other repository run: | cp cheatsheet.md /path/to/wiki-wag-repo cd /path/to/wiki-wag-repo git config user.email \u0026#34;your-email@example.com\u0026#34; git config user.name \u0026#34;Your Name\u0026#34; git add cheatsheet.md git commit -m \u0026#34;Sync cheatsheet from django-api repository\u0026#34; git push origin main Replace /path/to/wiki-wag-repo with the actual path to your local wiki-wag repository.\nCommit and Push Workflow:\nCommit the changes and push them to your Django API repository:\ngit add .github/workflows/sync_cheatsheet.yml git commit -m \u0026#34;Add sync cheatsheet workflow\u0026#34; git push origin main Run the Workflow:\nThe workflow will run automatically when you push changes to the main branch. It will copy the cheatsheet.md file to the specified path in the wiki-wag repository and commit the changes there.\nMake sure to replace the placeholder values in the workflow file (your-email@example.com, Your Name, and /path/to/wiki-wag-repo) with your actual email, name, and the path to the wiki-wag repository.\nHere are step-by-step instructions to set up the GitHub Actions workflow for syncing the cheatsheet.md file from the Django API repository to the wiki-wag repository:\nStep 1: Create the Workflow File Open your Django API repository in your code editor or on GitHub.\nInside the .github/workflows directory (create it if it doesn\u0026rsquo;t exist), create a new file named, for example, sync_cheatsheet.yml.\nCopy and paste the following content into sync_cheatsheet.yml:\nyamlCopy codename: Sync Cheatsheet on: push: branches: - main jobs: sync: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Copy cheatsheet to other repository run: | cp cheatsheet.md /path/to/wiki-wag-repo cd /path/to/wiki-wag-repo git config user.email \u0026#34;your-email@example.com\u0026#34; git config user.name \u0026#34;Your Name\u0026#34; git add cheatsheet.md git commit -m \u0026#34;Sync cheatsheet from django-api repository\u0026#34; git push origin main Replace /path/to/wiki-wag-repo, \u0026quot;your-email@example.com\u0026quot;, and \u0026quot;Your Name\u0026quot; with the actual path to your local wiki-wag repository, your email, and your GitHub username.\nStep 2: Commit and Push Workflow File In your terminal, navigate to the Django API repository.\nRun the following commands to stage, commit, and push the workflow file:\nbashCopy codegit add .github/workflows/sync_cheatsheet.yml git commit -m \u0026#34;Add sync cheatsheet workflow\u0026#34; git push origin main Step 3: Run the Workflow Visit the Actions tab on your GitHub repository to see the status of your workflow. You should see the \u0026ldquo;Sync Cheatsheet\u0026rdquo; workflow running or completed. Step 4: Verify Changes in the wiki-wag Repository After the workflow completes, check your wiki-wag repository for the synced changes to the cheatsheet.md file.\nIf there are any issues or changes are not reflected as expected, review the GitHub Actions logs for the workflow to identify potential errors.\nThat\u0026rsquo;s it! You\u0026rsquo;ve set up a GitHub Actions workflow to automatically sync the cheatsheet.md file from the Django API repository to the wiki-wag repository on each push to the main branch.\nBreak down the content of the GitHub Actions workflow file step by step: name: Sync Cheatsheet This line sets the name of the GitHub Actions workflow to \u0026ldquo;Sync Cheatsheet.\u0026rdquo; push: branches: - main This section specifies the trigger for the workflow. The workflow will be triggered on each push to the main branch. sync: runs-on: ubuntu-latest Here, we define a job named \u0026ldquo;sync\u0026rdquo; that will run on the latest version of the Ubuntu operating system. steps: - name: Checkout repository uses: actions/checkout@v2 This step checks out the code from the repository, allowing subsequent steps to operate on the repository\u0026rsquo;s contents. uses: actions/checkout@v2: This part specifies the action that will be used for this step. In GitHub Actions, an action is a reusable unit of code. The actions/checkout action is provided by GitHub and is commonly used to check out the source code of the repository. @v2: This refers to the version of the actions/checkout action to use. In this case, it\u0026rsquo;s version 2 of the action. The @v2 is a version tag that indicates a specific release or version of the action. Using a version tag ensures that the workflow is using a stable and known version of the action, making it less prone to unexpected changes. - name: Copy cheatsheet to other repository run: | cp cheatsheet.md /path/to/wiki-wag-repo cd /path/to/wiki-wag-repo In this step, the cheatsheet.md file is copied from the current repository to the specified path (/path/to/wiki-wag-repo). The subsequent commands are executed within the wiki-wag repository. git config user.email \u0026#34;your-email@example.com\u0026#34; git config user.name \u0026#34;Your Name\u0026#34; These commands set the global Git configuration for the user\u0026rsquo;s email and name in the wiki-wag repository. git add cheatsheet.md This command stages the changes to the cheatsheet.md file for the next commit. git commit -m \u0026#34;Sync cheatsheet from django-api repository\u0026#34; This command creates a new commit with a commit message indicating that the cheatsheet.md file is being synced from the django-api repository. git push origin main Finally, this command pushes the changes to the remote repository (origin) on the main branch.\nReal Case: If I have another branch othe then main in repo2 I can do it: name: Sync Cheatsheet on: push: branches: - main jobs: sync: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 with: ref: opzione-pagina # Specify the branch you want to sync Summary The GitHub Actions workflow automates the process of syncing the cheatsheet.md file from the django-api repository to the wiki-wag repository. It does so by copying the file, committing the changes, and pushing the commit to the main branch of the wiki-wag repository whenever changes are pushed to the main branch of the django-api repository.\nSome useful notes Merge: Creates Merge Commits: When you merge one branch into another, Git creates a new merge commit that has two parent commits: one from the branch you\u0026rsquo;re merging and another from the branch you\u0026rsquo;re merging into. This results in a non-linear history with multiple branches merging into each other Preserves Original History:\nThe original commits from both branches remain unchanged. This approach keeps a clear record of when changes were made on each branch.\nRebase: Linearizes History:\nRebase is used to linearize the commit history. It moves or combines a sequence of commits to a new base commit. When you rebase one branch onto another, it effectively transplants the entire branch onto the tip of the other branch, creating a linear history. No Merge Commits:\nUnlike merge, rebase doesn\u0026rsquo;t create additional merge commits. It can result in a cleaner, more linear history. When to Choose Each Approach: Merge:\nUse merge when you want to preserve the original commit history, especially when collaborating with others. Good for feature branches and when you want to maintain a clear record of branch integration points. Rebase:\nUse rebase when you want a clean, linear history and don\u0026rsquo;t mind rewriting commits. Useful for feature branches before merging into a shared branch to avoid unnecessary merge commits. Switch vs. Checkout: git switch is a more modern and user-friendly command introduced in recent versions of Git. It is designed specifically for branch switching. If you\u0026rsquo;re using a version of Git that supports git switch, you can replace git checkout with git switch:\nSwitching Branch: git switch template-tutorial Both commands essentially do the same thing in this context, but git switch provides a clearer and more explicit syntax for branch-related operations. If your Git version supports it, feel free to use git switch instead of git checkout.\nGIT CHEATSHEET git command to see the last 3 commit with oneline :\ngit log --oneline -n 3 HOOKS Hook per sincronizzare un file di testo da stckbit con l\u0026rsquo;intera directory proveniente dal local. Questo script è molto potente in quanto selettivamente recupera dal remote il file di interesse lo sovrascrive forzatamente nella locale e poi qualsiasi cambio in local sul file non viene considerato ## Mauro 1/5/24 - h. 13:11 #!/bin/bash # Fetch latest changes from the remote repository git fetch origin # Pull the latest version of cheatsheet.md from the remote and overwrite local changes git pull origin main --force # Remove any local changes to cheatsheet.md git checkout -- cheatsheet.md # Continue with the rest of the script # Add all changes to the staging area git add . # Commit all staged changes git commit -m \u0026#34;Auto-commit before pushing changes\u0026#34; # Push the commit to the remote repository git push origin main WAGTAIL How to use StreamField for mixed content StreamField block reference Templating - Jinja Wrinting Templates La regola da seguire è questa:\ncode: class wagtail.fields.StreamField(blocks, use_json_field=None, blank=False, min_num=None, max_num=None, block_counts=None, collapsed=False)\nE questa la spiegazione:\nclass wagtail.fields.StreamField: This line defines a class named StreamField in the wagtail.fields module.\n(blocks, use_json_field=None, blank=False, min_num=None, max_num=None, block_counts=None, collapsed=False): These are the parameters that the StreamField class constructor (init method) accepts. Let\u0026rsquo;s go through each one:\nblocks: This is a required parameter. It represents the blocks that can be used in the stream. It seems like it should be provided when creating an instance of StreamField.\nuse_json_field=None: This is an optional parameter with a default value of None. It allows you to specify whether to use a JSON field for storage. If not provided, it defaults to None.\nblank=False: This is an optional parameter with a default value of False. It indicates whether the field is allowed to be blank when used in a form. If not provided, it defaults to False.\nmin_num=None: This is an optional parameter with a default value of None. It specifies the minimum number of blocks required. If not provided, it defaults to None.\nmax_num=None: This is an optional parameter with a default value of None. It specifies the maximum number of blocks allowed. If not provided, it defaults to None.\nblock_counts=None: This is an optional parameter with a default value of None. It seems related to counting blocks. If not provided, it defaults to None.\ncollapsed=False: This is an optional parameter with a default value of False. It indicates whether the blocks should be collapsed in the Wagtail admin interface. If not provided, it defaults to False\nCosì ad esempio per questo codice. Possiamo effettuare il breakdown di questo codice in base alla regola definita:\n`class BlogPage(Page): author = models.CharField(max_length=255, default=\u0026lsquo;Default Author\u0026rsquo;) date = models.DateField(\u0026ldquo;Post date\u0026rdquo;)\nbody = StreamField( [ ('heading', blocks.CharBlock(form_classname=\u0026quot;title\u0026quot;)), ('paragraph', blocks.RichTextBlock()), ('image', ImageChooserBlock()), ('code', CodeBlock()), ('raw_html', RawHTMLBlock()), ], use_json_field=True ) content_panels = Page.content_panels + [ FieldPanel('author'), FieldPanel('date'), FieldPanel('body'), ] `\nauthor = models.CharField(max_length=255, default=\u0026lsquo;Default Author\u0026rsquo;): This line defines a character field named author in the BlogPage class. It has a maximum length of 255 characters and a default value of \u0026lsquo;Default Author\u0026rsquo;.\ndate = models.DateField(\u0026ldquo;Post date\u0026rdquo;): This line defines a date field named date in the BlogPage class with a human-readable name \u0026ldquo;Post date\u0026rdquo;.\nbody = StreamField([\u0026hellip;], use_json_field=True): This line defines a stream field named body in the BlogPage class. It allows the inclusion of different block types, such as CharBlock, RichTextBlock, ImageChooserBlock, CodeBlock, and RawHTMLBlock. The use_json_field parameter is set to True, indicating that a JSON field will be used for storage.\ncontent_panels = Page.content_panels + [\u0026hellip;]: This line defines the content panels for the Wagtail admin interface. It includes panels for \u0026lsquo;author\u0026rsquo;, \u0026lsquo;date\u0026rsquo;, and \u0026lsquo;body\u0026rsquo;.\nPoi in particolare:\ncontent_panels definition in the BlogPage class: content_panels = Page.content_panels + [ FieldPanel('author'), FieldPanel('date'), FieldPanel('body'), ]\nPage.content_panels: This part includes the content panels defined in the parent Page class. It allows the inclusion of standard page fields, such as title, slug, publish date, etc.\nFieldPanel(\u0026lsquo;author\u0026rsquo;): This adds a panel for the author field to the content panels. It\u0026rsquo;s likely a simple text input for the author\u0026rsquo;s name.\nFieldPanel(\u0026lsquo;date\u0026rsquo;): This adds a panel for the date field, probably a date picker for selecting the post date.\nFieldPanel(\u0026lsquo;body\u0026rsquo;): This adds a panel for the body field. Since it\u0026rsquo;s a StreamField, it might include a dynamic set of blocks like headings, paragraphs, images, code blocks, and raw HTML.\nUso dello StructBox in Wagtail Example Model with StructBlock Consider a simple model for a page with a StreamField containing a StructBlock named \u0026lsquo;person\u0026rsquo;:\n` # models.py from django.db import models from wagtail.core.fields import StreamField from wagtail.core import blocks from wagtail.images.blocks import ImageChooserBlock from wagtail.core.models import Page from wagtail.admin.edit_handlers import FieldPanel, StreamFieldPanel\nclass BlogPage(Page): body = StreamField([ (\u0026lsquo;person\u0026rsquo;, blocks.StructBlock([ (\u0026lsquo;first_name\u0026rsquo;, blocks.CharBlock()), (\u0026lsquo;surname\u0026rsquo;, blocks.CharBlock()), (\u0026lsquo;photo\u0026rsquo;, ImageChooserBlock(required=False)), (\u0026lsquo;biography\u0026rsquo;, blocks.RichTextBlock()), ])), (\u0026lsquo;heading\u0026rsquo;, blocks.CharBlock(form_classname=\u0026ldquo;title\u0026rdquo;)), (\u0026lsquo;paragraph\u0026rsquo;, blocks.RichTextBlock()), (\u0026lsquo;image\u0026rsquo;, ImageChooserBlock()), ], use_json_field=True)\ncontent_panels = Page.content_panels + [ StreamFieldPanel('body'), ] `\u0026lt;/span\u0026gt; Diagram Explanation Blog Page with StreamField and StructBlock:\nA BlogPage contains a StreamField named \u0026lsquo;body\u0026rsquo;. \u0026lsquo;body\u0026rsquo; includes various block types, one of which is a StructBlock named \u0026lsquo;person\u0026rsquo;. Person StructBlock:\nThe \u0026lsquo;person\u0026rsquo; block is a StructBlock containing fields like \u0026lsquo;first_name\u0026rsquo;, \u0026lsquo;surname\u0026rsquo;, \u0026lsquo;photo\u0026rsquo;, and \u0026lsquo;biography\u0026rsquo;. Block Instances:\nWhen editing a BlogPage, you can add multiple instances of different block types, including \u0026lsquo;person\u0026rsquo;. Each \u0026lsquo;person\u0026rsquo; block instance can have its own \u0026lsquo;first_name\u0026rsquo;, \u0026lsquo;surname\u0026rsquo;, \u0026lsquo;photo\u0026rsquo;, and \u0026lsquo;biography\u0026rsquo;\nTemplate Implementation\nTo render this in a template, you can use the following:\n`\u0026lt;!-- templates/blog_page.html --\u0026gt; {% extends \u0026#34;base.html\u0026#34; %} {% block content %} \u0026lt;article\u0026gt; {% for block in page.body %} {% if block.block_type == \u0026#39;person\u0026#39; %} \u0026lt;div class=\u0026#34;person\u0026#34;\u0026gt; {% if block.value.photo %} {% image block.value.photo width-400 %} {% endif %} \u0026lt;h2\u0026gt;{{ block.value.first_name }} {{ block.value.surname }}\u0026lt;/h2\u0026gt; {{ block.value.biography }} \u0026lt;/div\u0026gt; {% else %} {# Rendering for other block types #} \u0026lt;section class=\u0026#34;{{ block.block_type }}\u0026#34;\u0026gt; {% include_block block %} \u0026lt;/section\u0026gt; {% endif %} {% endfor %} \u0026lt;/article\u0026gt; {% endblock %} Database Initialization\nWhen you run makemigrations and migrate after adding the StructBlock to your model, the necessary database tables and fields are created. The use_json_field=True parameter in the StreamField indicates that the data for the StreamField will be stored as JSON in the database.\nHere\u0026rsquo;s how you perform the migration:\nbash Copy code python manage.py makemigrations python manage.py migrate After migration, you can create or edit a BlogPage instance through the Wagtail admin interface. The StructBlock fields will be part of the form for each \u0026lsquo;person\u0026rsquo; block within the \u0026lsquo;body\u0026rsquo; StreamField.\nRiferimenti Rapidi Wagtail Caso Studio web page How to use Streamfield for mixed content StreamFieldBlock Reference Caratteristiche avanzate di Diango - Wagtail Uno dei porblemi che si incontrano effettuando delle tabelle all\u0026rsquo;interno di wagtail ma in generale anche in Django è il caso pratico della renderizzazione degli headers di una tabella se si vogliono recuperare ad esempio i dati all\u0026rsquo;interno delle celle della tabella.\nQuesto codice di esempio effettua il debug su ciò che è successo:\n` {% for column in block.value.columns %} {{ column.header|default:\u0026ldquo;Column Header\u0026rdquo; }}\n\u0026lt;!-- Debugging statements --\u0026gt; \u0026lt;p\u0026gt;block.value.rows: {{ block.value.rows|list }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;block.value.rows.1: {{ block.value.rows|list.1|default:\u0026quot;\u0026quot; }}\u0026lt;/p\u0026gt; {% with block.value.rows|list.1|default:\u0026quot;\u0026quot; as row_values %} {{ row_values.0|default:\u0026quot;\u0026quot; }} {% endwith %} \u0026lt;/th\u0026gt; {% endfor %} \u0026lt;/tr\u0026gt; \u0026lt;th\u0026gt; Column Header \u0026lt;!-- Debugging statements --\u0026gt; \u0026lt;p\u0026gt;block.value.rows: \u0026amp;lt;generator object TypedTable.rows at 0x7f08958de2e0\u0026amp;gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;block.value.rows.1: \u0026lt;/p\u0026gt; ` Approfondendo la ricerca si artriva a tale indicazione :::caution The issue seems to be related to the fact that block.value.rows is a generator object. In Python, generators are lazy and can be consumed only once. If you try to iterate through the generator more than once, you will get an empty result on subsequent iterations.\nIn your case, it seems like the generator has been consumed once, which is why when you try to access block.value.rows.1, it doesn\u0026rsquo;t contain any values.\nTo address this issue, you might want to convert the generator to a list so that you can iterate through it multiple times. However, since you are using the TypedTableBlock from wagtail.contrib.typed_table_block, you might need to adjust how you access the rows.\nHere is a modification that converts the generator to a list before using it:\ndjango Copy code\n\u0026lt;!-- Debugging statements --\u0026gt; \u0026lt;p\u0026gt;block.value.rows: {{ block.value.rows|list }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;block.value.rows.1: {{ block.value.rows|list.1|default:\u0026quot;\u0026quot; }}\u0026lt;/p\u0026gt; {% with block.value.rows|list.1|default:\u0026quot;\u0026quot; as row_values %} {{ row_values.0|default:\u0026quot;\u0026quot; }} {% endwith %} \u0026lt;/th\u0026gt; {% endfor %} \u0026lt;/tr\u0026gt; WAGTAIL Upgrade process We recommend upgrading one feature release at a time, even if your project is several versions behind the current one. This has a number of advantages over skipping directly to the newest release:\nIf anything breaks as a result of the upgrade, you will know which version caused it, and will be able to troubleshoot accordingly;\nDeprecation warnings shown in the console output will notify you of any code changes you need to make before upgrading to the following version;\nSome releases make database schema changes that need to be reflected on your project by running ./manage.py makemigrations - this is liable to fail if too many schema changes happen in one go.\nBefore upgrading to a new feature release:\nCheck your project’s console output for any deprecation warnings, and fix them where necessary;\nCheck the new version’s release notes, and the Compatible Django / Python versions table below, for any dependencies that need upgrading first;\nMake a backup of your database.\nTo upgrade:\nUpdate the wagtail line in your project’s requirements.txt file to specify the latest patch release of the version you wish to install. For example, to upgrade to version 1.8.x, the line should read: `wagtail\u0026gt;=1.8,\u0026lt;1.9 Run:\npip install -r requirements.txt ./manage.py makemigrations ./manage.py migrate`\nMake any necessary code changes as directed in the “Upgrade considerations” section of the release notes.\nTest that your project is working as expected.\nRemember that the JavaScript and CSS files used in the Wagtail admin may have changed between releases - if you encounter erratic behaviour on upgrading, ensure that you have cleared your browser cache. When deploying the upgrade to a production server, be sure to run ./manage.py collectstatic to make the updated static files available to the web server. In production, we recommend enabling ManifestStaticFilesStorage in the STATICFILES_STORAGE setting - this ensures that different versions of files are assigned distinct URLs.\nWAGTAIL COMPATIBILITY WITH DJANGO - link PYTHON Spiegazione attraverso codice di init, getattribute e super Spesso nei moduli di wagtail si fa riferimento alla classazione e subclassazione. Avere chiri alcuni termini è necessario. Questa è la breve sintesi attraverso un sempio\nclass Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;)` This is a simple class representing a vehicle with a brand. It has an init method that initializes the brand attribute and a start method to print a message when the vehicle starts. Car (inherits from Vehicle):\npython Copy code class Car(Vehicle): def init(self, brand, model): # No use of super() ​ self.model = model\ndef start(self): print(f\u0026quot;{self.brand} {self.model} car started.\u0026quot;) This class represents a specific type of vehicle, a Car, inheriting from the Vehicle class. It has its own init method, but it doesn\u0026rsquo;t use super(), and it has a start method that overrides the start method in the Vehicle class. CarWithSuper (inherits from Car):\nclass CarWithSuper(Car): def init(self, brand, model, color): super().init(brand, model) self.color = color\ndef start(self): super().start() print(f\u0026quot;The {self.color} car is ready to go.\u0026quot;) def __getattribute__(self, name): # Modifying __getattribute__ to add a prefix to the brand attribute if name == \u0026quot;brand\u0026quot;: return \u0026quot;Awesome \u0026quot; + super().__getattribute__(name) else: return super().__getattribute__(name) This class inherits from Car and introduces a new attribute color. It uses super() in the init method to call the init method of the parent class (Car). It overrides the start method, calls the parent\u0026rsquo;s start method using super(), and adds an additional message. It also modifies getattribute to add a prefix (\u0026ldquo;Awesome\u0026rdquo;) to the brand attribute. Examples: Example without super(), init, and getattribute:\ncar_without_super = Car(brand=\u0026quot;Toyota\u0026quot;, model=\u0026quot;Camry\u0026quot;) print(car_without_super.model) # Output: Camry An instance of Car is created without using super(). __init__ in Car is called, but __init__ of the parent (Vehicle) is not called. start method from Vehicle is not available in car_without_super. Example with super(), __init__, and __getattribute__: car_with_super = CarWithSuper(brand=\u0026quot;Ford\u0026quot;, model=\u0026quot;Mustang\u0026quot;, color=\u0026quot;red\u0026quot;) print(car_with_super.brand) # Output: Awesome Ford car_with_super.start() # Output: Ford Mustang car started. The red car is ready to go.\nAn instance of CarWithSuper is created using super() to call init of the parent (Car). getattribute is modified to add a prefix to the brand attribute. start method calls the parent\u0026rsquo;s (Car) start method using super() and adds an additional message. Roles:\ninit: Used for initializing the attributes of an object. In the inheritance chain, it\u0026rsquo;s common to use super().init(\u0026hellip;) to call the initializer of the parent class.\ngetattribute: Called whenever an attribute of an object is accessed. Can be modified to customize attribute access. Used here to modify the behavior of accessing the brand attribute.\nsuper(): Used to refer to the parent class. In init, it\u0026rsquo;s used to call the initializer of the parent class. In methods, it\u0026rsquo;s used to call methods from the parent class. In the provided example, super() helps maintain the hierarchy in inheritance, ensuring that the methods of the parent classes are appropriately called. init is used for object initialization, and getattribute is modified to customize attribute access.\nVediamo ora cosa succede se non utilizziamo i metodi Assenza di init If you don\u0026rsquo;t use the init method in the Vehicle class, the class will still be valid, but instances of the class won\u0026rsquo;t have a constructor to initialize their state. The init method is a special method in Python classes that is automatically called when an object is created. It is used for initializing the attributes of the object.\nHere\u0026rsquo;s what happens when you don\u0026rsquo;t include init:\npython Copy code class Vehicle: def start(self): print(\u0026ldquo;Vehicle started.\u0026rdquo;)\nCreating an instance without init vehicle_instance = Vehicle()\nThis will not raise an error, but the instance won\u0026rsquo;t have a \u0026lsquo;brand\u0026rsquo; attribute. If you try to access \u0026lsquo;brand\u0026rsquo;, it will result in an AttributeError. print(vehicle_instance.start()) # Output: Vehicle started. print(vehicle_instance.brand) # AttributeError: \u0026lsquo;Vehicle\u0026rsquo; object has no attribute \u0026lsquo;brand\u0026rsquo; In the example above, creating an instance of Vehicle without an init method is allowed. However, without an init method, instances won\u0026rsquo;t have any attributes initialized during instantiation. If you try to access an attribute that hasn\u0026rsquo;t been defined, you will get an AttributeError.\nIncluding the init method allows you to initialize the state of an object when it is created. For example:\npython Copy code class Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;) Creating an instance with init vehicle_instance = Vehicle(brand=\u0026ldquo;Toyota\u0026rdquo;)\nNow, the 'brand' attribute is initialized during instantiation. print(vehicle_instance.start()) # Output: Toyota vehicle started. print(vehicle_instance.brand) # Output: Toyota In the second example, the init method is used to initialize the brand attribute when a Vehicle instance is created. This ensures that the instance has a properly initialized state from the beginning.\nEd ora quando posso usare e non usare getattribute? If you don\u0026rsquo;t define the getattribute method in a class, Python will use the default behavior for attribute access. The default behavior involves looking up the attribute in the object\u0026rsquo;s dictionary and returning its value if found. If the attribute is not found in the object\u0026rsquo;s dictionary, Python looks for the attribute in the class hierarchy.\nHere\u0026rsquo;s what happens if you don\u0026rsquo;t use getattribute:\npython Copy code class Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;) Creating an instance without getattribute vehicle_instance = Vehicle(brand=\u0026ldquo;Toyota\u0026rdquo;)\nAccessing the \u0026lsquo;brand\u0026rsquo; attribute without a custom getattribute print(vehicle_instance.brand) # Output: Toyota\nThe default behavior is used, and there is no need for a custom getattribute in this case. In the example above, we create a Vehicle class with an init method to initialize the brand attribute. When we access the brand attribute, the default attribute access behavior is used, and there is no need for a custom getattribute. The attribute is found in the instance\u0026rsquo;s dictionary, and its value is returned.\nThe getattribute method is a powerful tool for customizing attribute access, and it allows you to intercept attribute access calls and customize the behavior. However, in many cases, you may not need to override it, and the default behavior is sufficient for basic attribute access. Only when you need to customize the attribute access behavior should you consider defining a getattribute method.\nIn the example provided, the getattribute method is used to customize the behavior of accessing the brand attribute in the CarWithSuper class. Specifically, it adds a prefix (\u0026ldquo;Awesome\u0026rdquo;) to the value of the brand attribute before returning it.\nHere\u0026rsquo;s the relevant part of the code:\npython Copy code class CarWithSuper(Car): # \u0026hellip;\ndef __getattribute__(self, name): # Modifying __getattribute__ to add a prefix to the brand attribute if name == \u0026quot;brand\u0026quot;: return \u0026quot;Awesome \u0026quot; + super().__getattribute__(name) else: return super().__getattribute__(name) In this case, the getattribute method is modifying the behavior of accessing the brand attribute. Without this customization, accessing car_with_super.brand would simply return the value of the brand attribute. With the custom getattribute, it returns the value with the added prefix.\nSo, you might need to use getattribute when you want to customize or intercept attribute access calls and modify the behavior based on your specific requirements. It\u0026rsquo;s a powerful tool, but it should be used judiciously, as unnecessary or incorrect use may lead to unexpected behavior and potential issues.\nMIXIN L\u0026rsquo;esempio esposto e che di seguito si ripropone risulta anche un ottimo esempio di mixin\nYes, the provided example with Vehicle, Car, and CarWithSuper can be considered an example of mixin-like behavior. Let me break it down:\nVehicle Class:\npython Copy code class Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;) This is the base class representing a generic vehicle. It has an init method to initialize the brand attribute and a start method.\nCar Class (Inherits from Vehicle):\npython Copy code class Car(Vehicle): def init(self, brand, model): super().init(brand) self.model = model\ndef start(self): print(f\u0026quot;{self.brand} {self.model} car started.\u0026quot;) The Car class inherits from Vehicle. It has its own init method but uses super() to call the init method of the parent class (Vehicle). It also has its own start method, overriding the start method of Vehicle.\nCarWithSuper Class (Inherits from Car):\npython Copy code class CarWithSuper(Car): def init(self, brand, model, color): super().init(brand, model) self.color = color\ndef start(self): super().start() print(f\u0026quot;The {self.color} car is ready to go.\u0026quot;) def __getattribute__(self, name): if name == \u0026quot;brand\u0026quot;: return \u0026quot;Awesome \u0026quot; + super().__getattribute__('brand') else: return super().__getattribute__(name) The CarWithSuper class inherits from Car and introduces a new attribute (color). It uses super() to call the init method of the parent class (Car). It also overrides the start method, calling the parent\u0026rsquo;s (Car) start method using super() and adding an additional message. Additionally, it modifies getattribute to add a prefix (\u0026ldquo;Awesome\u0026rdquo;) to the brand attribute.\nSo, in this example, the classes are organized in a way that exhibits mixin-like behavior. The CarWithSuper class enhances the behavior of the Car class by adding attributes and modifying methods, and it uses super() to maintain the hierarchy and call methods from parent classes. While it may not strictly adhere to the classic definition of a mixin, it shares some characteristics of mixin-like behavior.\nDefinizione di mixin In object-oriented programming, a mixin is a class that provides a certain functionality to be inherited by a subclass, but is not meant to stand alone. Mixins are used to enhance the functionality of a class without the need for multiple inheritance.\nHere are some key characteristics and features of mixins:\nPurpose-Specific Functionality: Mixins are designed to provide a specific set of functionalities or behaviors that can be easily added to other classes. They encapsulate a piece of behavior.\nReusability: Mixins promote code reuse. Instead of duplicating code in multiple classes, you can create a mixin and include it in various classes that need that particular behavior.\nNo Standalone Use: Mixins are not meant to be instantiated or used independently. They lack the complete implementation to be used as standalone classes. They are intended to be combined with other classes.\nFlexible Composition: Since a class can inherit from multiple mixins, it allows for flexible composition of functionalities. This is in contrast to languages that do not support multiple inheritance directly.\nAvoids Diamond Problem: Mixins can help avoid the \u0026ldquo;diamond problem\u0026rdquo; that arises in languages with multiple inheritance, where a class inherits from two classes that have a common ancestor.\nSmall and Focused: Mixins are typically small and focused on a specific task. This makes them easy to understand, maintain, and reuse.\nTHE subprocess Module: Wrapping Programs With Python If you’ve ever wanted to simplify your command-line scripting or use Python alongside command-line applications—or any applications for that matter—then the Python subprocess module can help. From running shell commands and command-line applications to launching applications, the Python subprocess module can help.\nProcesses and Subprocesses First off, you might be wondering why there’s a sub in the Python subprocess module name. And what exactly is a process, anyway? Whenever you use a computer, you’ll always be interacting with programs. A process is the operating system’s abstraction of a running program. So, using a computer always involve processes. Start menus, app bars, command-line interpreters, text editors, browsers, and more—every application comprises one or more processes.\nA typical operating system will report hundreds or even thousands of running processes. However, central processing units (CPUs) typically only have a handful of cores, which means that they can only run a handful of instructions simultaneously. So, you may wonder how thousands of processes can appear to run at the same time.\nIn short, the operating system is a marvelous multitasker—as it has to be. The CPU is the brain of a computer, but it operates at the timescale. Most other components of a computer are far slower than the CPU. For instance, a magnetic hard disk read takes thousands of times longer than a typical CPU operation.\nIf a process needs to write something to the hard drive, or wait for a response from a remote server, then the CPU would sit idle most of the time. Multitasking keeps the CPU busy.\nPart of what makes the operating system so great at multitasking is that it’s fantastically organized too. The operating system keeps track of processes in a process table or process control block. In this table, you’ll find the process’s file handles, security context, references to its address spaces, and more.\nThe process table allows the operating system to abandon a particular process at will, because it has all the information it needs to come back and continue with the process at a later time. A process may be interrupted many thousands of times during execution, but the operating system always finds the exact point where it left off upon returning.\nAn operating system doesn’t boot up with thousands of processes, though. Many of the processes you’re familiar with are started by you. In the next section, you’ll look into the lifetime of a process.\nProcess Lifetime Think of how you might start a Python application from the command line. This is an instance of your command-line process starting a Python process:\nThe process that starts another process is referred to as the parent, and the new process is referred to as the child. The parent and child processes run mostly independently. Sometimes the child inherits specific resources or contexts from the parentand nformation about processes is kept in a table. Each process keeps track of its parents, which allows the process hierarchy to be represented as a tree.\nProcess Creation Mechanism on Unix-based Systems Here\u0026rsquo;s a breakdown of the process creation mechanism on Unix-based systems, focusing on the key concepts and functionalities:\n1. fork() System Call:\nThe foundation of process creation in Unix systems is the fork() system call. When a process calls fork(), the kernel creates a copy of the calling process. This copy is called the child process, while the original process becomes the parent process. Both parent and child processes share the same memory space initially. This might seem inefficient, but it allows for quick process creation and efficient memory sharing when needed. 2. Process Identifier (PID):\nThe kernel assigns a unique identifier, called a Process Identifier (PID), to each process. This PID helps the system differentiate between processes and manage their resources. After the fork() call, both the parent and child process receive the PID of the child process as the return value. However, they can distinguish their own identity using functions like getpid(). 3. The Exec Family of Functions:\nOnce a child process is created with fork(), it typically doesn\u0026rsquo;t continue executing the original program\u0026rsquo;s code. The child process usually replaces its code and data space with a new program using functions like execve(), execvp(), or others from the exec family. These functions take the path to the executable file and optional arguments as input. By replacing its code with the new program, the child process essentially starts executing a completely different program. 4. Memory Management:\nAfter fork(), the parent and child processes share the same memory space. However, any changes made by one process are not reflected immediately in the other\u0026rsquo;s memory. When either process modifies memory, a technique called copy-on-write is employed. The kernel creates a copy of the modified memory page for the modifying process, allowing them to have independent memory regions for further changes. 5. Resource Inheritance:\nThe child process inherits most resources from the parent process, including file descriptors, open files, signal handlers (with some exceptions), and environment variables. This inheritance simplifies program execution as the child process inherits a ready-made environment. Overall Flow:\nParent process calls fork(). Kernel creates a copy of the parent process (child process). Both parent and child receive the child\u0026rsquo;s PID. Child process usually replaces its code with a new program using exec functions. Memory management employs copy-on-write to maintain independent memory spaces for parent and child. Child process inherits most resources from the parent. Additional Notes:\nThis explanation provides a basic overview. There are additional details and complexities involved in process creation, like process states, scheduling, and signals. The wait() system call allows the parent process to wait for the child process to finish execution. Inter-process communication (IPC) mechanisms enable processes to communicate and share data after creation. This knowledge should provide a solid foundation for understanding process creation on Unix-based systems. You can explore further details in resources like the Unix man pages for fork(), exec, and related functions.\nInteraction with fork() with user / application /OS/Hardware fork system call interacts with these components on a Unix-based system:\n1. User Initiates Action:\nThe process starts with a user initiating an action. This could involve launching an application or performing some task within an existing application. 2. Application Requests New Process (Optional):\nThe application itself might not directly call fork. However, in some cases, an application might request the creation of a new process to handle a specific subtask within the application. This would involve the application making a system call (not directly fork itself) to the operating system to create a new process. 3. Operating System Kernel and fork():\nThe core interaction happens at the operating system kernel level. When fork() is called (either by the application or the kernel itself for some reason), the kernel creates a copy of the existing process. This copied process is called the child process, and the original process becomes the parent process. 4. Memory and Resource Management:\nThe kernel needs to manage resources for both the parent and child processes. This includes memory, CPU time, and access to devices. Initially, both parent and child processes share the same memory space. However, a technique called copy-on-write (COW) is often used to optimize memory usage. With COW, memory pages are only copied when either process tries to modify them. 5. Hardware and Process Execution:\nThe hardware itself (CPU, memory, devices) doesn\u0026rsquo;t directly understand fork. It operates based on instructions provided by the kernel. The kernel manages the context switching between the parent and child processes, ensuring each gets a slice of CPU time to execute instructions. Overall Interaction Summary:\nThe fork system call primarily interacts with the operating system kernel. It triggers the creation of a new process and the kernel manages the resource allocation (including memory) for both parent and child processes. The hardware executes instructions provided by the kernel for both processes, and the kernel employs context switching to ensure efficient CPU utilization.\nImportant Note:\nThe diagram you sent depicts a high-level view of system components. The fork system call and process creation happen within the operating system kernel, which is not explicitly shown in the diagram.\nFlow representing the fork system call at the kernel level on Unix-based systems: Components:\nParent Process: This represents the existing process before calling fork. It has its own memory space, registers, and program counter (PC) holding the current instruction. Kernel (Fork System Call): This symbolizes the core of the operating system responsible for handling fork. Process Descriptor Table (PDT): This table maintains information about all processes in the system, including the parent process. Memory Management Unit (MMU): This hardware component translates virtual addresses used by processes to physical memory addresses. Memory (Code, Data, Stack): This represents the memory space containing the program code, data, and stack of the parent process. Process of fork:\nfork System Call: The parent process initiates the fork system call through a system call interface. Kernel Creates Child Process Descriptor: The kernel allocates a new entry in the Process Descriptor Table (PDT) for the child process. This entry will hold information about the child process, including its state and resources. Memory Space Copying (Logical): The kernel doesn\u0026rsquo;t physically copy the entire memory space of the parent process initially. Instead, it creates a copy of the memory mappings for the child process in the MMU. Both parent and child processes share the same physical memory pages until one of them tries to modify the data. Registers and Program Counter Copying: The kernel copies the values of all CPU registers from the parent process to the child process. This ensures the child process starts execution at the same instruction point as the parent process when it called fork. New File Descriptors and Resources: The kernel allocates new file descriptors and other resources (like open network connections) for the child process. These resources might be shared or duplicated depending on the specific resource type. Post-fork State:\nThe parent and child processes now exist as independent entities with their own process descriptors, memory mappings, and registers. They share the same physical memory pages initially (through copy-on-write), but any modifications by either process will trigger a copy of the modified page for that specific process. Both processes are typically in a \u0026ldquo;ready\u0026rdquo; state, waiting to be scheduled for CPU execution by the kernel. Additional Notes:\nThis is a simplified diagram, and the actual implementation of fork can vary depending on the specific operating system. The diagram doesn\u0026rsquo;t show the hardware itself (CPU, memory) but represents the interaction through the MMU. Context switching between parent and child processes is managed by the kernel after fork. I hope this visual representation provides a clearer understanding of how fork works at the kernel level. Feel free to ask if you have any further questions about specific details in the diagram.\nThe parent-child relationship between a process and its subprocess isn’t always the same. Sometimes the two processes will share specific resources, like inputs and outputs, but sometimes they won’t. Sometimes child processes live longer than the parent. A child outliving the parent can lead to orphaned or zombie processes, though more discussion about those is outside the scope of this tutorial.\nWhen a process has finished running, it’ll usually end. Every process, on exit, should return an integer. This integer is referred to as the return code or exit status. Zero is synonymous with success, while any other value is considered a failure. Different integers can be used to indicate the reason why a process has failed.\nIn the same way that you can return a value from a function in Python, the operating system expects an integer return value from a process once it exits. This is why the canonical C main() function usually returns an integer:\nC `// minimal_program.c int main(){ return 0; }` This example shows a minimal amount of C code necessary for the file to compile with gcc without any warnings. It has a main() function that returns an integer. When this program runs, the operating system will interpret its execution as successful since it returns zero.\nActive Processes on Your System You may be curious to see what processes are running on your system right now. To do that, you can use platform-specific utilities to track them:\nWindows Linux + macOS For UNIX-based systems, there are many command-line utilities to choose from:\ntop: The classic process and resource monitor, often installed by default. Once it’s running, to see the tree view, also called the forest view, press Shift+V. The forest view may not work on the default macOS top. htop: More advanced and user-friendly version of top. atop: Another version of top with more information, but more technical. bpytop: A Python implementation of top with nice visuals. pstree: A utility specifically to explore the process tree. On macOS, you also have the Activity Monitor application in your utilities. In the View menu, if you select All Processes, Hierarchically, you should be able to see your process tree.\nYou can also explore the Python psutil library, which allows you to retrieve running process information on both Windows and UNIX-based systems.\nOne universal attribute of process tracking across systems is that each process has a process identification number, or PID, which is a unique integer to identify the process within the context of the operating system. You’ll see this number on most of the utilities listed above.\nAlong with the PID, it’s typical to see the resource usage, such as CPU percentage and amount of RAM that a particular process is using. This is the information that you look for if a program is hogging all your resources.\nThe resource utilization of processes can be useful for developing or debugging scripts that use the subprocess module, even though you don’t need the PID, or any information about what resources processes are using in the code itself. While playing with the examples that are coming up, consider leaving a representation of the process tree open to see the new processes pop up.\nYou now have a bird’s-eye view of processes. You’ll deepen your mental model throughout the tutorial, but now it’s time to see how to start your own processes with the Python subprocess module.\nOverview of the Python subprocess Module The Python subprocess module is for launching child processes. These processes can be anything from GUI applications to the shell. The parent-child relationship of processes is where the sub in the subprocess name comes from. When you use subprocess, Python is the parent that creates a new child process. What that new child process is, is up to you.\nPython subprocess was originally proposed and accepted for Python 2.4 as an alternative to using the os module. Some documented changes have happened as late as 3.8. The examples in this article were tested with Python 3.10.4, but you only need 3.8+ to follow along with this tutorial.\nMost of your interaction with the Python subprocess module will be via the run() function. This blocking function will start a process and wait until the new process exits before moving on.\nThe documentation recommends using run() for all cases that it can handle. For edge cases where you need more control, the Popen class can be used. Popen is the underlying class for the whole subprocess module. All functions in the subprocess module are convenience wrappers around the Popen() constructor and its instance methods. Near the end of this tutorial, you’ll dive into the Popen class. You may come across other functions like call(), check_call(), and check_output(), but these belong to the older subprocess API from Python 3.5 and earlier. Everything these three functions do can be replicated with the newer run() function. The older API is mainly still there for backwards compatibility, and you won’t cover it in this tutorial.\nThere’s also a fair amount of redundancy in the subprocess module, meaning that there are various ways to achieve the same end goal. You won’t be exploring all variations in this tutorial. What you will find, though, are robust techniques that should keep you on the right path.\nBasic Usage of the Python subprocess Module In this section, you’ll take a look at some of the most basic examples demonstrating the usage of the subprocess module. You’ll start by exploring a bare-bones command-line timer program with the run() function.\nBasic Usage of the Python subprocess In this section, you’ll take a look at some of the most basic examples demonstrating the usage of the subprocess module. You’ll start by exploring a bare-bones command-line timer program with the run() function.\nThe Timer Example To come to grips with the Python subprocess module, you’ll want a bare-bones program to run and experiment with. For this, you’ll use a program written in Python:\nfrom argparse import ArgumentParser from time import sleep parser = ArgumentParser() parser.add_argument(\u0026#34;duration\u0026#34;, type=int) # Changed argument name to \u0026#34;duration\u0026#34; args = parser.parse_args() print(f\u0026#34;Starting timer of {args.duration} seconds\u0026#34;) for _ in range(args.duration): print(\u0026#34;**\u0026#34;, end=\u0026#34;\u0026#34;, flush=True) sleep(1) print(\u0026#34;Bravo Mauuro!\u0026#34;) ``` enter code hereThe timer program uses to accept an integer as an argument. The integer represents the number of seconds that the timer should wait until exiting, which the program uses sleep() to achieve. It’ll play a small animation representing each passing second until it exits:\nIt’s not much, but the key is that it serves as a cross-platform process that runs for a few seconds and which you can easily tinker with. You’ll be calling it with subprocess as if it were a separate executable.\nEach item in the sequence represents a token which is used for a system call to start a new process.\nThe Use of subprocess to Run Any App With subprocess, you aren’t limited to text-based applications like the shell. You can call any application that you can with the Start menu or app bar, as long as you know the precise name or path of the program that you want to run:\nPython\n\u0026gt;\u0026gt;\u0026gt; subprocess.run([\u0026quot;gedit\u0026quot;]) CompletedProcess(args=['gedit'], returncode=0)\nDepending on your Linux distribution, you may have a different text editor, such as kate, leafpad, kwrite, or enki.\nThese commands should open up a text editor window. Usually CompletedProcess won’t get returned until you close the editor window. Yet in the case of macOS, since you need to run the launcher process open to launch TextEdit, the CompletedProcess gets returned straight away.\nLauncher processes are in charge of launching a specific process and then ending. Sometimes programs, such as web browsers, have them built in. The mechanics of launcher processes is out of the scope of this tutorial, but suffice to say that they’re able to manipulate the operating system’s process tree to reassign parent-child relationships.\nNote: There are many problems that you might initially reach for subprocess to solve, but then you’ll find a specific module or library that solves it for you. This tends to be a theme with subprocess since it is quite a low-level utility.\nAn example of something that you might want to do with subprocess is to open a web browser to a specific page. However, for that, it’s probably best to use the Python module webbrowser. The webbrowser module uses subprocess under the hood but handles all the finicky cross-platform and browser differences that you might encounter.\nThen again, subprocess can be a remarkably useful tool to get something done quickly. If you don’t need a full-fledged library, then subprocess can be your Swiss Army knife. It all depends on your use case. More discussion on this topic will come later.\nYou’ve successfully started new processes using Python! That’s subprocess at its most basic. Next up, you’ll take a closer look at the CompletedProcess object that’s returned from run().\nThe CompletedProcess Object When you use run(), the return value is an instance of the CompletedProcess class. As the name suggests, run() returns the object only once the child process has ended. It has various attributes that can be helpful, such as the args that were used for the process and the returncode.\nTo see this clearly, you can assign the result of run() to a variable, and then access its attributes such as .returncode:\nPython\n`\u0026raquo;\u0026gt; import subprocess\ncompleted_process = subprocess.run([\u0026ldquo;python\u0026rdquo;, \u0026ldquo;timer.py\u0026rdquo;]) usage: timer.py [-h] time timer.py: error: the following arguments are required: time\ncompleted_process.returncode 2`\nThe process has a return code that indicates failure, but it doesn’t raise an exception. Typically, when a subprocess process fails, you’ll always want an exception to be raised, which you can do by passing in a check=True argument:\nPython\n\u0026gt;\u0026gt;\u0026gt; completed_process = subprocess.run( ... [\u0026quot;python\u0026quot;, \u0026quot;timer.py\u0026quot;], ... check=True ... ) ... usage: timer.py [-h] time timer.py: error: the following arguments are required: time Traceback (most recent call last): ... subprocess.CalledProcessError: Command '['python', 'timer.py']' returned non-zero exit status 2.\nThere are various ways to deal with failures, some of which will be covered in the next section. The important point to note for now is that run() won’t necessarily raise an exception if the process fails unless you’ve passed in a check=True argument.\nThe CompletedProcess also has a few attributes relating to input/output (I/O), which you’ll cover in more detail in the communicating with processes section. Before communicating with processes, though, you’ll learn how to handle errors when coding with subprocess.\nsubprocess Exceptions As you saw earlier, even if a process exits with a return code that represents failure, Python won’t raise an exception. For most use cases of the subprocess module, this isn’t ideal. If a process fails, you’ll usually want to handle it somehow, not just carry on.\nA lot of subprocess use cases involve short personal scripts that you might not spend much time on, or at least shouldn’t spend much time on. If you’re tinkering with a script like this, then you’ll want subprocess to fail early and loudly.\nCalledProcessError for Non-Zero Exit Code If a process returns an exit code that isn’t zero, you should interpret that as a failed process. Contrary to what you might expect, the Python subprocess module does not automatically raise an exception on a non-zero exit code. A failing process is typically not something you want your program to pass over silently, so you can pass a check=True argument to run() to raise an exception:\nPython\n\u0026gt;\u0026gt;\u0026gt; completed_process = subprocess.run( ... [\u0026quot;python\u0026quot;, \u0026quot;timer.py\u0026quot;], ... check=True ... ) ... usage: timer.py [-h] time timer.py: error: the following arguments are required: time Traceback (most recent call last): ... subprocess.CalledProcessError: Command '['python', 'timer.py']' returned non-zero exit status 2.\nThe CalledProcessError is raised as soon as the subprocess runs into a non-zero return code. If you’re developing a short personal script, then perhaps this is good enough for you. If you want to handle errors more gracefully, then read on to the section on exception handling.\nOne thing to bear in mind is that the CalledProcessError does not apply to processes that may hang and block your execution indefinitely. To guard against that, you’d want to take advantage of the timeout parameter.\nTimeoutExpired for Processes That Take Too Long Sometimes processes aren’t well behaved, and they might take too long or just hang indefinitely. To handle those situations, it’s always a good idea to use the timeout parameter of the run() function.\nPassing a timeout=1 argument to run() will cause the function to shut down the process and raise a TimeoutExpired error after one second:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nsubprocess.run([\u0026ldquo;python\u0026rdquo;, \u0026ldquo;timer.py\u0026rdquo;, \u0026ldquo;5\u0026rdquo;], timeout=1) Starting timer of 5 seconds .Traceback (most recent call last): \u0026hellip; subprocess.TimeoutExpired: Command \u0026lsquo;[\u0026lsquo;python\u0026rsquo;, \u0026rsquo;timer.py\u0026rsquo;, \u0026lsquo;5\u0026rsquo;]\u0026rsquo; timed out after 1.0 seconds`\nIn this example, the first dot of the timer animation was output, but the subprocess was shut down before being able to complete.\nThe other type of error that might happen is if the program doesn’t exist on that particular system, which raises one final type of error.\nFileNotFoundError for Programs That Don’t Exist The final type of exception you’ll be looking at is the FileNotFoundError, which is raised if you try and call a program that doesn’t exist on the target system:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nsubprocess.run([\u0026ldquo;now_you_see_me\u0026rdquo;]) Traceback (most recent call last): \u0026hellip; FileNotFoundError: The system cannot find the file specified`\nThis type of error is raised no matter what, so you don’t need to pass in any arguments for the FileNotFoundError.\nThose are the main exceptions that you’ll run into when using the Python subprocess module. For many use cases, knowing the exceptions and making sure that you use timeout and check arguments will be enough. That’s because if the subprocess fails, then that usually means that your script has failed.\nHowever, if you have a more complex program, then you may want to handle errors more gracefully. For instance, you may need to call many processes over a long period of time. For this, you can use the try … except construct.\nAn Example of Exception Handling Here’s a code snippet that shows the main exceptions that you’ll want to handle when using subprocess:\n`import subprocess try: subprocess.run( [\u0026#34;python\u0026#34;, \u0026#34;timer.py\u0026#34;, \u0026#34;5\u0026#34;], timeout=10, check=True ) except FileNotFoundError as exc: print(f\u0026#34;Process failed because the executable could not be found.\\n{exc}\u0026#34;) except subprocess.CalledProcessError as exc: print( f\u0026#34;Process failed because did not return a successful return code. \u0026#34; f\u0026#34;Returned {exc.returncode}\\n{exc}\u0026#34; ) except subprocess.TimeoutExpired as exc: print(f\u0026#34;Process timed out.\\n{exc}\u0026#34;)` This snippet shows you an example of how you might handle the three main exceptions raised by the subprocess module.\nNow that you’ve used subprocess in its basic form and handled some exceptions, it’s time to get familiar with what it takes to interact with the shell.\nIntroduction to the Shell and Text-Based Programs With subprocess Some of the most popular use cases of the subprocess module are to interact with text-based programs, typically available on the shell. That’s why in this section, you’ll start to explore all the moving parts involved when interacting with text-based programs, and perhaps question if you need the shell at all!\nThe shell is typically synonymous with the command-line interface or CLI, but this terminology isn’t entirely accurate. There are actually two separate processes that make up the typical command-line experience:\nThe interpreter, which is typically thought of as the whole CLI. Common interpreters are Bash on Linux, Zsh on macOS, or PowerShell on Windows. In this tutorial, the interpreter will be referred to as the shell. The interface, which displays the output of the interpreter in a window and sends user keystrokes to the interpreter. The interface is a separate process from the shell, sometimes called a terminal emulator. When on the command line, it’s common to think that you’re interacting directly with the shell, but you’re really interacting with the interface. The interface takes care of sending your commands to the shell and displaying the shell’s output back to you.\nWith this important distinction in mind, it’s time to turn your attention to what run() is actually doing. It’s common to think that calling run() is somehow the same as typing a command in a terminal interface, but there are important differences.\nWhile all new process are created with the same system calls, the context from which the system call is made is different. The run() function can make a system call directly and doesn’t need to go through the shell to do so:\nIn fact, many programs that are thought of as shell programs, such as Git, are really just text-based programs that don’t need a shell to run. This is especially true of UNIX environments, where all of the familiar utilities like ls, rm, grep, and cat are actually separate executables that can be called directly:\nPython\n`\u0026raquo;\u0026gt; # Linux or macOS\nimport subprocess subprocess.run([\u0026ldquo;ls\u0026rdquo;]) timer.py CompletedProcess(args=[\u0026rsquo;ls\u0026rsquo;], returncode=0)`\nThere are some tools that are specific to shells, though. Finding tools embedded within the shell is far more common on Windows shells like PowerShell, where commands like ls are part of the shell itself and not separate executables like they are in a UNIX environment:\nPython\n`\u0026raquo;\u0026gt; # Windows\nimport subprocess subprocess.run([\u0026ldquo;ls\u0026rdquo;]) Traceback (most recent call last): \u0026hellip; FileNotFoundError: [WinError 2] The system cannot find the file specified`\nIn PowerShell, ls is the default alias for Get-ChildItem, but calling that won’t work either because Get-ChildItem isn’t a separate executable—it’s part of PowerShell itself.\nThe fact that many text-based programs can operate independently from the shell may make you wonder if you can cut out the middle process—namely, the shell—and use subprocess directly with the text-based programs typically associated with the shell.\nUse Cases for the Shell and subprocess There are a few common reasons why you might want to call the shell with the Python subprocess module:\nWhen you know certain commands are only available via the shell, which is more common in Windows When you’re experienced in writing shell scripts with a particular shell, so you want to leverage your ability there to do certain tasks while still working primarily in Python When you’ve inherited a large shell script that might do nothing that Python couldn’t do, but would take a long time to reimplement in Python This isn’t an exhaustive list!\nYou might use the shell to wrap programs or to do some text processing. However, the syntax can be very cryptic when compared to Python. With Python, text processing workflows are easier to write, easier to maintain, generally more performant, and cross-platform to boot. So it’s well worth considering going without the shell.\nWhat often happens, though, is that you just don’t have the time or it’s not worth the effort to reimplement existing shell scripts in Python. In those cases, using subprocess for some sloppy Python isn’t a bad thing!\nCommon reasons for using subprocess itself are similar in nature to using the shell with subprocess:\nWhen you have to use or analyze a black box, or even a white box When you want a wrapper for an application When you need to launch another application As an alternative to basic shell scripts Note: A black box could be a program that can be freely used but whose source code isn’t available, so there’s no way to know exactly what it does and no way to modify its internals.\nSimilarly, a white box could be a program whose source code is available but can’t be changed. It could also be a program whose source code you could change, but its complexity means that it would take you a long time to get your head around it to be able to change it.\nIn these cases, you can use subprocess to wrap your boxes of varying opacity, bypassing any need to change or reimplement things in Python.\nOften you’ll find that for subprocess use cases, there will be a dedicated library for that task. Later in the tutorial, you’ll examine a script that creates a Python project, complete with a virtual environment and a fully initialized Git repository. However, the Cookiecutter and Copier libraries already exist for that purpose.\nEven though specific libraries might be able to do your task, it may still be worth doing things with subprocess. For one, it might be much faster for you to execute what you already know how to do, rather than learning a new library.\nAdditionally, if you’re sharing this script with friends or colleagues, it’s convenient if your script is pure Python without any other dependencies, especially if your script needs to go on minimal environments like servers or embedded systems.\nHowever, if you’re using subprocess instead of pathlib to read and write a few files with Bash, you might want to consider learning how to read and write with Python. Learning how to read and write files doesn’t take long, and it’ll definitely be worth it for such a common task.\nWith that out of the way, it’s time to get familiar with the shell environments on both Windows and UNIX-based systems.\nBasic Usage of subprocess With UNIX-Based Shells To run a shell command using run(), the args should contain the shell that you want to use, the flag to indicate that you want it to run a specific command, and the command that you’re passing in:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nsubprocess.run([\u0026ldquo;bash\u0026rdquo;, \u0026ldquo;-c\u0026rdquo;, \u0026ldquo;ls /usr/bin | grep pycode\u0026rdquo;]) pycodestyle pycodestyle-3 pycodestyle-3.10 CompletedProcess(args=[\u0026lsquo;bash\u0026rsquo;, \u0026lsquo;-c\u0026rsquo;, \u0026rsquo;ls /usr/bin | grep pycode\u0026rsquo;], returncode=0)`\nHere a common shell command is demonstrated. It uses ls piped into grep to filter some of the entries. The shell is handy for this kind of operation because you can take advantage of the pipe operator (|). You’ll cover pipes in more detail later.\nYou can replace bash with the shell of your choice. The -c flag stands for command, but may be different depending on the shell that you’re using. This is almost the exact equivalent of what happens when you add the shell=True argument:\nPython\n\u0026gt;\u0026gt;\u0026gt; subprocess.run([\u0026quot;ls /usr/bin | grep pycode\u0026quot;], shell=True) pycodestyle pycodestyle-3 pycodestyle-3.10 CompletedProcess(args=['ls /usr/bin | grep pycode'], returncode=0)\nThe shell=True argument uses [\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, ...] behind the scenes, so it’s almost the equivalent of the previous example.\nNote: On UNIX-based systems, the sh shell was traditionally the Bourne shell. That said, the Bourne shell is now quite old, so many operating systems use sh as a link to Bash or Dash.\nThis can often be different from the shell used with the terminal interface that you interact with. For instance, since macOS Catalina, the default shell that you’ll find on the command-line app has changed from Bash to Zsh, yet sh often still points to Bash. Likewise, on Ubuntu, sh points to Dash, but the default that you typically interact with on the command-line application is still Bash.\nSo, calling sh on your system may result in a different shell than what is found in this tutorial. Nevertheless, the examples should all still work.\nYou’ll note that the token after \u0026quot;-c\u0026quot; should be one single token, with all the spaces included. Here you’re giving control to the shell to parse the command. If you were to include more tokens, this would be interpreted as more options to pass to the shell executable, not as additional commands to run inside the shell.\nA Security Warning If at any point you plan to get user input and somehow translate that to a call to subprocess, then you have to be very careful of injection attacks. That is, take into account potential malicious actors. There are many ways to cause havoc if you just let people run code on your machine.\nTo use a very simplistic example, where you take user input and send it, unfiltered, to subprocess to run on the shell:\n- [Windows](https://realpython.com/python-subprocess/#windows-3) - [Linux + macOS](https://realpython.com/python-subprocess/#linux-macos-3) Python `# unsafe_program.py import subprocess # ... subprocess.run([\u0026#34;bash\u0026#34;, \u0026#34;-c\u0026#34;, f\u0026#34;ls {input()}\u0026#34;]) # ...` You can imagine the intended use case is to wrap ls and add something to it. So the expected user behavior is to provide a path like \u0026quot;/home/realpython/\u0026quot;. However, if a malicious actor realized what was happening, they could execute almost any code they wanted. Take the following, for instance, but be careful with this:\n/home/realpython/; echo 'You could've been hacked: rm -rf /*'\nAgain, beware! These innocent-looking lines could try and delete everything on the system! In this case the malicious part is in quotes, so it won’t run, but if the quotes were not there, you’d be in trouble. The key part that does this is the call to rm with the relevant flags to recursively delete all files, folders, and subfolders, and it’ll work to force the deletion through. It can run the echo and potentially the rm as entirely separate commands by adding semicolons, which act as command separators allowing what would usually be multiple lines of code to run on one line.\nRunning these malicious commands would cause irreparable damage to the file system, and would require reinstalling the operating system. So, beware!\nLuckily, the operating system wouldn’t let you do this to some particularly important files. The rm command would need to use sudo in UNIX-based systems, or be run as an administrator in Windows to be completely successful in its mayhem. The command would probably delete a lot of important stuff before stopping, though.\nSo, make sure that if you’re dynamically building user inputs to feed into a subprocess call, then you’re very careful! With that warning, coming up you’ll be covering using the outputs of commands and chaining commands together—in short, how to communicate with processes once they’ve started.\nCommunication With Processes You’ve used the subprocess module to execute programs and send basic commands to the shell. But something important is still missing. For many tasks that you might want to use subprocess for, you might want to dynamically send inputs or use the outputs in your Python code later.\nTo communicate with your process, you first should understand a little bit about how processes communicate in general, and then you’ll take a look at two examples to come to grips with the concepts.\nThe Standard I/O Streams A stream at its most basic represents a sequence of elements that aren’t available all at once. When you read characters and lines from a file, you’re working with a stream in the form of a file object, which at its most basic is a file descriptor. File descriptors are often used for streams. So, it’s not uncommon to see the terms stream, file, and file-like used interchangeably.\nWhen processes are initialized, there are three special streams that a process makes use of. A process does the following:\nReads stdin for input Writes to stdout for general output Writes to stderr for error reporting These are the standard streams—a cross-platform pattern for process communication.\nSometimes the child process inherits these streams from the parent. This is what’s happening when you use subprocess.run() in the REPL and are able to see the output of the command. The stdout of the Python interpreter is inherited by the subprocess.\nWhen you’re in a REPL environment, you’re looking at a command-line interface process, complete with the three standard I/O streams. The interface has a shell process as a child process, which itself has a Python REPL as a child. In this situation, unless you specify otherwise, stdin comes from the keyboard, while stdout and stderr are displayed on-screen. The interface, the shell, and the REPL share the streams:\nYou can think of the standard I/O streams as byte dispensers. The subprocess fills up stdout and stderr, and you fill up stdin. Then you read the bytes in stdout and stderr, and the subprocess reads from stdin.\nAs with a dispenser, you can stock stdin before it gets linked up to a child process. The child process will then read from stdin as and when it needs to. Once a process has read from a stream, though, the bytes are dispensed. You can’t go back and read them again:\nThese three streams, or files, are the basis for communicating with your process. In the next section, you’ll start to see this in action by getting the output of a magic number generator program.\nThe Magic Number Generator Example Often, when using the subprocess module, you’ll want to use the output for something and not just display the output as you have been doing so far. In this section, you’ll use a magic number generator that outputs, well, a magic number.\nImagine that the magic number generator is some obscure program, a black box, inherited across generations of sysadmins at your job. It outputs a magic number that you need for your secret calculations. You’ll read from the stdout of subprocess and use it in your wrapper Python program:\nPython\n`# magic_number.py\nfrom random import randint\nprint(randint(0, 1000))`\nOkay, not really so magical. That said, it’s not the magic number generator that you’re interested in—it’s interacting with a hypothetical black box with subprocess that’s interesting. To grab the number generator’s output to use later, you can pass in a capture_output=True argument to run():\nPython\n`\u0026raquo;\u0026gt; import subprocess\nmagic_number_process = subprocess.run( \u0026hellip; [\u0026ldquo;python\u0026rdquo;, \u0026ldquo;magic_number.py\u0026rdquo;], capture_output=True \u0026hellip; ) magic_number_process.stdout b'769\\n\u0026rsquo;`\nPassing a capture_output argument of True to run() makes the output of the process available at the .stdout attribute of the completed process object. You’ll note that it’s returned as a bytes object, so you need to be mindful of encodings when reading it.\nAlso note that the .stdout attribute of the CompletedProcess is no longer a stream. The stream has been read, and it’s stored as a bytes object in the .stdout attribute.\nWith the output available, you can use more than one subprocess to grab values and operate on them in your code:\nPython `\u0026gt;\u0026gt;\u0026gt; import subprocess \u0026gt;\u0026gt;\u0026gt; sum( ... int( ... subprocess.run( ... [\u0026quot;python\u0026quot;, \u0026quot;magic_number.py\u0026quot;], capture_output=True ... ).stdout ... ) ... for _ in range(2) ... ) 1085` In this example, you start two magic number processes that fetch two magic numbers and then add them together. For now, you rely on the automatic decoding of the bytes object by the int() constructor. In the next section, though, you’ll learn how to decode and encode explicitly.\nThe Decoding of Standard Streams Processes communicate in bytes, and you have a few different ways to deal with encoding and decoding these bytes. Beneath the surface, subprocess has a few ways of getting into text mode.\nText mode means that subprocess will try to take care of encoding itself. To do that, it needs to know what character encoding to use. Most of the options for doing this in subprocess will try to use the default encoding. However, you generally want to be explicit about what encoding to use to prevent a bug that would be hard to find in the future.\nYou can pass a text=True argument for Python to take care of encodings using the default encoding. But, as mentioned, it’s always safer to specify the encodings explicitly using the encoding argument, as not all systems work with the nearly universal UTF-8:\nPython\n`\u0026raquo;\u0026gt; magic_number_process = subprocess.run( \u0026hellip; [\u0026ldquo;python\u0026rdquo;, \u0026ldquo;magic_number.py\u0026rdquo;], capture_output=True, encoding=\u0026ldquo;utf-8\u0026rdquo; \u0026hellip; ) \u0026hellip;\nmagic_number_process.stdout \u0026lsquo;647\\n\u0026rsquo;`\nIf in text mode, the .stdout attribute on a CompletedProcess is now a string and not a bytes object.\nYou can also decode the bytes returned by calling the .decode() method on the stdout attribute directly, without requiring text mode at all:\nPython\n`\u0026raquo;\u0026gt; magic_number_process = subprocess.run( \u0026hellip; [\u0026ldquo;python\u0026rdquo;, \u0026ldquo;magic_number.py\u0026rdquo;], capture_output=True \u0026hellip; ) \u0026hellip;\nmagic_number_process.stdout.decode(\u0026ldquo;utf-8\u0026rdquo;) \u0026lsquo;72\\n\u0026rsquo;`\nThere are other ways to put run() into text mode. You can also set a True value for errors or universal_newlines, which will also put run() into text mode. This may seem redundant, but much of this is kept for backwards compatibility, seeing as the subprocess module has changed over the years.\nNow that you know how to read and decode the output of a process, it’s time to take a look at writing to the input of a process.\nReaction Game Example In this section, you’ll use subprocess to interact with a command-line game. It’s a basic program that’s designed to test a human’s reaction time. With your knowledge of standard I/O streams, though, you’ll be able to hack it! The source code of the game makes use of the time and random module:\nPython\n`# reaction_game.py\nfrom time import perf_counter, sleep from random import random\nprint(\u0026ldquo;Press enter to play\u0026rdquo;) input() print(\u0026ldquo;Ok, get ready!\u0026rdquo;) sleep(random() * 5 + 1) print(\u0026ldquo;go!\u0026rdquo;) start = perf_counter() input() end = perf_counter() print(f\u0026quot;You reacted in {(end - start) * 1000:.0f} milliseconds!\\nGoodbye!\u0026quot;)`\nThe program starts, asks for the user to press enter, and then after a random amount of time will ask the user to press enter again. It measures from the time the message appears to the time the user presses enter, or at least that’s what the game developer thinks:\nThe input() function will read from stdin until it reaches a newline, which means an Enter keystroke in this context. It returns everything it consumed from stdin except the newline. With that knowledge, you can use subprocess to interact with this game:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nprocess = subprocess.run( \u0026hellip; [\u0026ldquo;python\u0026rdquo;, \u0026ldquo;reaction_game.py\u0026rdquo;], input=\u0026quot;\\n\\n\u0026quot;, encoding=\u0026ldquo;utf-8\u0026rdquo; \u0026hellip; ) \u0026hellip; Press enter to play Ok, get ready! go! You reacted in 0 milliseconds! Goodbye!`\nA reaction time of 0 milliseconds! Not bad! Considering the average human reaction time is around 270 milliseconds, your program is definitely superhuman. Note that the game rounds its output, so 0 milliseconds doesn’t mean it’s instantaneous.\nThe input argument passed to run() is a string consisting of two newlines. The encoding parameter is set to utf-8, which puts run() into text mode. This sets up the process for it to receive the input you that give it.\nBefore the program starts, stdin is stocked, waiting for the program to consume the newlines it contains. One newline is consumed to start the game, and the next newline is consumed to react to go!.\nNow that you know what’s happening—namely that stdin can be stocked, as it were—you can hack the program yourself without subprocess. If you start the game and then press Enter a few times, that’ll stock up stdin with a few newlines that the program will automatically consume once it gets to the input() line. So your reaction time is really only the time it takes for the reaction game to execute start = time() and consume an input:\nThe game developer gets wise to this, though, and vows to release another version, which will guard against this exploit. In the meantime, you’ll peek a bit further under the hood of subprocess and learn about how it wires up the standard I/O streams.\nPipes and the Shell To really understand subprocesses and the redirection of streams, you really need to understand pipes and what they are. This is especially true if you want to wire up two processes together, feeding one stdout into another process’s stdin, for instance. In this section, you’ll be coming to grips with pipes and how to use them with the subprocess module.\nIntroduction to Pipes A pipe, or pipeline, is a special stream that, instead of having one file handle as most files do, has two. One handle is read-only, and the other is write-only. The name is very descriptive—a pipe serves to pipe a byte stream from one process to another. It’s also buffered, so a process can write to it, and it’ll hold onto those bytes until it’s read, like a dispenser.\nYou may be used to seeing pipes on the command line, as you did in the section on shells:\nShell\n$ ls /usr/bin | grep python\nThis command tells the shell to create an ls process to list all the files in /usr/bin. The pipe operator (|) tells the shell to create a pipe from the stdout of the ls process and feed it into the stdin of the grep process. The grep process filters out all the lines that don’t contain the string python.\nWindows doesn’t have grep, but a rough equivalent of the same command would be as follows:\nWindows PowerShell\nPS\u0026gt; ls \u0026quot;C:\\Program Files\u0026quot; | Out-String -stream | Select-String windows\nHowever, on Windows PowerShell, things work very differently. As you learned in the Windows shell section of this tutorial, the different commands are not separate executables. Therefore, PowerShell is internally redirecting the output of one command into another without starting new processes.\nNote: If you don’t have access to a UNIX-based operating system but have Windows 10 or above, then you actually do have access to a UNIX-based operating system! Check out Windows Subsystem for Linux, which will give you access to a fully featured Linux shell.\nYou can use pipes for different processes on PowerShell, though getting into the intricacies of which ones is outside the scope of this tutorial. For more information on PowerShell pipes, check out the documentation. So, for the rest of the pipe examples, only UNIX-based examples will be used, as the basic mechanism is the same for both systems. They’re not nearly as common on Windows, anyway.\nIf you want to let the shell take care of piping processes into one another, then you can just pass the whole string as a command into subprocess:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nsubprocess.run([\u0026ldquo;sh\u0026rdquo; , \u0026ldquo;-c\u0026rdquo;, \u0026ldquo;ls /usr/bin | grep python\u0026rdquo;]) python3 python3-config python3.8 python3.8-config \u0026hellip; CompletedProcess(\u0026hellip;)`\nThis way, you can let your chosen shell take care of piping one process into another, instead of trying to reimplement things in Python. This is a perfectly valid choice in certain situations.\nLater in the tutorial, you’ll also come to see that you can’t pipe processes directly with run(). For that, you’ll need the more complicated Popen(). Actual piping is demonstrated in Connecting Two Porcesses Together With Pipes, near the end of the tutorial.\nWhether you mean to pipe one process into another with the subprocess module or not, the subprocess module makes extensive use of pipes behind the scenes.\nThe Pipes of subprocess The Python subprocess module uses pipes extensively to interact with the processes that it starts. In a previous example, you used the capture_output parameter to be able to access stdout:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nmagic_number_process = subprocess.run( \u0026hellip; [\u0026ldquo;python\u0026rdquo;, \u0026ldquo;magic_number.py\u0026rdquo;], capture_output=True \u0026hellip; ) magic_number_process.stdout b'769\\n\u0026rsquo;`\ncapture_output=True is equivalent to explicitly setting the stdout and stderr parameters to the subprocess.PIPE constant:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nmagic_number_process = subprocess.run( \u0026hellip; [\u0026ldquo;python\u0026rdquo;, \u0026ldquo;magic_number.py\u0026rdquo;], \u0026hellip; stdout=subprocess.PIPE, \u0026hellip; stderr=subprocess.PIPE \u0026hellip; ) \u0026hellip; magic_number_process.stdout b'769\\n\u0026rsquo;`\nThe PIPE constant is nothing special. It’s just a number that indicates to subprocess that a pipe should be created. The function then creates a pipe to link up to the stdout of the subprocess, which the function then reads into the CompletedProcess object’s stdout attribute. By the time it’s a CompletedProcess, it’s no longer a pipe, but a bytes object that can be accessed multiple times.\nNote: Pipe buffers have a limited capacity. Depending on the system you are running on, you may easily run into that limit if you plan on holding large quantities of data in the buffer. To work around this limit, you can use normal files.\nYou can also pass a file object to any of the standard stream parameters:\nPython\n`\u0026raquo;\u0026gt; from tempfile import TemporaryFile\nwith TemporaryFile() as f: \u0026hellip; ls_process = subprocess.run([\u0026ldquo;python\u0026rdquo;, \u0026ldquo;magic_number.py\u0026rdquo;], stdout=f) \u0026hellip; f.seek(0) \u0026hellip; print(f.read().decode(\u0026ldquo;utf-8\u0026rdquo;)) \u0026hellip; 0 554`\nYou can’t pass a bytes object or a string directly to the stdin argument, though. It needs to be something file-like.\nNote that the 0 that gets returned first is from the call to seek() which returns the new stream position, which in this case is the start of the stream.\nThe input parameter is similar to the capture_output parameter in that it’s a shortcut. Using the input parameter will create a buffer to store the contents of input, and then link the file up to the new process to serve as its stdin.\nTo actually link up two processes with a pipe from within subprocess is something that you can’t do with run(). Instead, you can delegate the plumbing to the shell, as you did earlier in the Introduction to the Shell and Text Based Programs with subprocess section.\nIf you needed to link up different processes without delegating any of the work to the shell, then you could do that with the underlying Popen() constructor. You’ll cover Popen() in a later section. In the next section, though, you’ll be simulating a pipe with run() because in most cases, it’s not vital for processes to be linked up directly.\nPipe Simulation With run() Though you can’t actually link up two processes together with a pipe by using the run() function, at least not without delegating it to the shell, you can simulate piping by judicious use of the stdout attribute.\nIf you’re on a UNIX-based system where almost all typical shell commands are separate executables, then you can just set the input of the second process to the .stdout attribute of the first CompletedProcess:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nls_process = subprocess.run([\u0026ldquo;ls\u0026rdquo;, \u0026ldquo;/usr/bin\u0026rdquo;], stdout=subprocess.PIPE) grep_process = subprocess.run( \u0026hellip; [\u0026ldquo;grep\u0026rdquo;, \u0026ldquo;python\u0026rdquo;], input=ls_process.stdout, stdout=subprocess.PIPE \u0026hellip; ) print(grep_process.stdout.decode(\u0026ldquo;utf-8\u0026rdquo;)) python3 python3-config python3.8 python3.8-config \u0026hellip;`\nHere the .stdout attribute of the CompletedProcess object of ls is set to the input of the grep_process. It’s important that it’s set to input rather than stdin. This is because the .stdout attribute isn’t a file-like object. It’s a bytes object, so it can’t be used as an argument to stdin.\nAs an alternative, you can operate directly with files too, setting them to the standard stream parameters. When using files, you set the file object as the argument to stdin, instead of using the input parameter:\nPython\n`\u0026raquo;\u0026gt; import subprocess\nfrom tempfile import TemporaryFile with TemporaryFile() as f: \u0026hellip; ls_process = subprocess.run([\u0026ldquo;ls\u0026rdquo;, \u0026ldquo;/usr/bin\u0026rdquo;], stdout=f) \u0026hellip; f.seek(0) \u0026hellip; grep_process = subprocess.run( \u0026hellip; [\u0026ldquo;grep\u0026rdquo;, \u0026ldquo;python\u0026rdquo;], stdin=f, stdout=subprocess.PIPE \u0026hellip; ) \u0026hellip; 0 # from f.seek(0) print(grep_process.stdout.decode(\u0026ldquo;utf-8\u0026rdquo;)) python3 python3-config python3.8 python3.8-config \u0026hellip;`\nAs you learned in the previous section, for Windows PowerShell, doing something like this doesn’t make a whole lot of sense because most of the time, these utilities are part of PowerShell itself. Because you aren’t dealing with separate executables, piping becomes less of a necessity. However, the pattern for piping is still the same if something like this needs to be done.\nWith most of the tools out the way, it’s now time to think about some practical applications for subprocess.\nPractical Ideas When you have an issue that you want to solve with Python, sometimes the subprocess module is the easiest way to go, even though it may not be the most correct.\nUsing subprocess is often tricky to get working across different platforms, and it has inherent dangers. But even though it may involve some sloppy Python, using subprocess can be a very quick and efficient way to solve a problem.\nAs mentioned, for most tasks you can imagine doing with subprocess, there’s usually a library out there that’s dedicated to that specific task. The library will almost certainly use subprocess, and the developers will have worked hard to make the code reliable and to cover all the corner cases that can make using subprocess difficult.\nSo, even though dedicated libraries exist, it can often be simpler to just use subprocess, especially if you’re in an environment where you need to limit your dependencies.\nIn the following sections, you’ll be exploring a couple of practical ideas.\nCreating a New Project: An Example Say you often need to create new local projects, each complete with a virtual environment and initialized as a Git repository. You could reach for the Cookiecutter library, which is dedicated to that task, and that wouldn’t be a bad idea.\nHowever, using Cookiecutter would mean learning Cookiecutter. Imagine you didn’t have much time, and your environment was extremely minimal anyway—all you could really count on was Git and Python. In these cases, subprocess can quickly set up your project for you:\nPython\n`# create_project.py\nfrom argparse import ArgumentParser from pathlib import Path import subprocess\ndef create_new_project(name): project_folder = Path.cwd().absolute() / name project_folder.mkdir() (project_folder / \u0026ldquo;README.md\u0026rdquo;).touch() with open(project_folder / \u0026ldquo;.gitignore\u0026rdquo;, mode=\u0026ldquo;w\u0026rdquo;) as f: f.write(\u0026quot;\\n\u0026quot;.join([\u0026ldquo;venv\u0026rdquo;, \u0026ldquo;pycache\u0026rdquo;])) commands = [ [ \u0026ldquo;python\u0026rdquo;, \u0026ldquo;-m\u0026rdquo;, \u0026ldquo;venv\u0026rdquo;, f\u0026quot;{project_folder}/venv\u0026quot;, ], [\u0026ldquo;git\u0026rdquo;, \u0026ldquo;-C\u0026rdquo;, project_folder, \u0026ldquo;init\u0026rdquo;], [\u0026ldquo;git\u0026rdquo;, \u0026ldquo;-C\u0026rdquo;, project_folder, \u0026ldquo;add\u0026rdquo;, \u0026ldquo;.\u0026rdquo;], [\u0026ldquo;git\u0026rdquo;, \u0026ldquo;-C\u0026rdquo;, project_folder, \u0026ldquo;commit\u0026rdquo;, \u0026ldquo;-m\u0026rdquo;, \u0026ldquo;Initial commit\u0026rdquo;], ] for command in commands: try: subprocess.run(command, check=True, timeout=60) except FileNotFoundError as exc: print( f\u0026quot;Command {command} failed because the process \u0026quot; f\u0026quot;could not be found.\\n{exc}\u0026quot; ) except subprocess.CalledProcessError as exc: print( f\u0026quot;Command {command} failed because the process \u0026quot; f\u0026quot;did not return a successful return code.\\n{exc}\u0026quot; ) except subprocess.TimeoutExpired as exc: print(f\u0026quot;Command {command} timed out.\\n {exc}\u0026quot;)\nif name == \u0026ldquo;main\u0026rdquo;: parser = ArgumentParser() parser.add_argument(\u0026ldquo;project_name\u0026rdquo;, type=str) args = parser.parse_args() create_new_project(args.project_name)`\nThis is a command-line tool that you can call to start a project. It’ll take care of creating a README.md file and a .gitignore file, and then it’ll run a few commands to create a virtual environment, initialize a git repository, and perform your first commit. It’s even cross-platform, opting to use pathlib to create the files and folders, which abstracts away the operating system differences.\nCould this be done with Cookiecutter? Could you use GitPython for the git part? Could you use the venv module to create the virtual environment? Yes to all. But if you just need something quick and dirty, using commands you already know, then just using subprocess can be a great option.\nChanging Extended Attributes If you use Dropbox, you may not know that there’s a way to ignore files when syncing. For example, you can keep virtual environments in your project folder and use Dropbox to sync the code, but keep the virtual environment local.\nThat said, it’s not as easy as adding a .dropboxignore file. Rather, it involves adding special attributes to files, which can be done from the command line. These attributes are different between UNIX-like systems and Windows:\nWindows Linux macOS Shell\n$ attr -s com.dropbox.ignored -V 1 \\ /home/yourname/Dropbox/YourFileName.pdf\nThere are some UNIX-based projects, like dropboxignore, that use shell scripts to make it easier to ignore files and folders. The code is relatively complex, and it won’t work on Windows.\nWith the subprocess module, you can wrap the different shell commands quite easily to come up with your own utility:\nPython\n``# dropbox_ignore.py\nimport platform from pathlib import Path from subprocess import run, DEVNULL\ndef init_shell(): print(\u0026ldquo;initializing shell\u0026rdquo;) system = platform.system() print(f\u0026quot;{system} detected\u0026quot;) if system == \u0026ldquo;Linux\u0026rdquo;: return Bash_shell() elif system == \u0026ldquo;Windows\u0026rdquo;: return Pwsh_shell() elif system == \u0026ldquo;Darwin\u0026rdquo;: raise NotImplementedError\nclass Pwsh_shell(): def init(self) -\u0026gt; None: try: run([\u0026ldquo;pwsh\u0026rdquo;, \u0026ldquo;-V\u0026rdquo;], stdout=DEVNULL, stderr=DEVNULL) self.shell = \u0026ldquo;pwsh\u0026rdquo; except FileNotFoundError as exc: print(\u0026ldquo;Powershell Core not installed, falling back to PowerShell\u0026rdquo;) self.shell = \u0026ldquo;powershell\u0026rdquo;\n@staticmethod def _make_string_path_list(paths: list[Path]) -\u0026gt; str: return \u0026quot;', '\u0026quot;.join(str(path).replace(\u0026quot;'\u0026quot;, \u0026quot;`'\u0026quot;) for path in paths) def ignore_folders(self, paths: list[Path]) -\u0026gt; None: path_list = self._make_string_path_list(paths) command = ( f\u0026quot;Set-Content -Path '{path_list}' \u0026quot; f\u0026quot;-Stream com.dropbox.ignored -Value 1\u0026quot; ) run([self.shell, \u0026quot;-NoProfile\u0026quot;, \u0026quot;-Command\u0026quot;, command], check=True) print(\u0026quot;Done!\u0026quot;) class Bash_shell(): @staticmethod def _make_string_path_list(paths: list[Path]) -\u0026gt; str: return \u0026ldquo;\u0026rsquo; \u0026lsquo;\u0026quot;.join(str(path).replace(\u0026rdquo;\u0026rsquo;\u0026quot;, \u0026ldquo;\\\u0026rsquo;\u0026rdquo;) for path in paths)\ndef ignore_folders(self, paths: list[Path]) -\u0026gt; None: path_list = self._make_string_path_list(paths) command = ( f\u0026quot;for f in '{path_list}'\\n do\\n \u0026quot; f\u0026quot;attr -s com.dropbox.ignored -V 1 $f\\ndone\u0026quot; ) run([\u0026quot;bash\u0026quot;, \u0026quot;-c\u0026quot;, command], check=True) print(\u0026quot;Done!\u0026quot;)`` This is a simplified snippet from the author’s dotDropboxIgnore repository. The init_shell() function detects the operating system with the platform module and returns an object that’s an abstraction around the system-specific shell. The code hasn’t implemented the behavior on macOS, so it raises a NotImplementedError if it detects it’s running on macOS.\nThe shell object allows you to call an .ignore_folders() method with a list of pathlib Path objects to set Dropbox to ignore those files.\nOn the Pwsh_shell class, the constructor tests to see if PowerShell Core is available, and if not, will fall back to the older Windows PowerShell, which is installed by default on Windows 10.\nIn the next section, you’ll review some of the other modules that might be interesting to keep in mind when deciding whether to use subprocess.\nPython Modules Associated With subprocess When deciding whether a certain task is a good fit for subprocess, there are some associated modules that you may want to be aware of.\nBefore subprocess existed, you could use os.system() to run commands. However, as with many things that os was used for before, standard library modules have come to replace os, so it’s mostly used internally. There are hardly any use cases for using os yourself.\nThere’s an official documentation page where you can examine some of the old ways to accomplish tasks with os and learn how you might do the same with subprocess.\nIt might be tempting to think that subprocess can be used for concurrency, and in simple cases, it can be. But, in line with the sloppy Python philosophy, it’s probably only going to be to hack something together quickly. If you want something more robust, then you’ll probably want to start looking at the multiprocessing module.\nDepending on the task that you’re attempting, you may be able to accomplish it with the asyncio or threading modules. If everything is written in Python, then these modules are likely your best bet.\nThe asyncio module has a high-level API to create and manage subprocesses too, so if you want more control over non-Python parallel processes, that might be one to check out.\nNow it’s time to get deep into subprocess and explore the underlying Popen class and its constructor.\nThe Popen Class As mentioned, the underlying class for the whole subprocess module is the Popen class and the Popen() constructor. Each function in subprocess calls the Popen() constructor under the hood. Using the Popen() constructor gives you lots of control over the newly started subprocesses.\nAs a quick summary, run() is basically the Popen() class constructor, some setup, and then a call to the .communicate() method on the newly initialized Popen object. The .communicate() method is a blocking method that returns the stdout and stderr data once the process has ended.\nThe name of Popen comes from a similar UNIX command that stands for pipe open. The command creates a pipe and then starts a new process that invokes the shell. The subprocess module, though, doesn’t automatically invoke the shell.\nThe run() function is a blocking function, which means that interacting dynamically with a process isn’t possible with it. However, the Popen() constructor starts a new process and continues, leaving the process running in parallel.\nThe developer of the reaction game that you were hacking earlier has released a new version of their game, one in which you can’t cheat by loading stdin with newlines:\nPython\n`# reaction_game_v2.py\nfrom random import choice, random from string import ascii_lowercase from time import perf_counter, sleep\nprint( \u0026ldquo;A letter will appear on screen after a random amount of time,\\n\u0026rdquo; \u0026ldquo;when it appears, type the letter as fast as possible \u0026quot; \u0026ldquo;and then press enter\\n\u0026rdquo; ) print(\u0026ldquo;Press enter when you are ready\u0026rdquo;) input() print(\u0026ldquo;Ok, get ready!\u0026rdquo;) sleep(random() * 5 + 2) target_letter = choice(ascii_lowercase) print(f\u0026rdquo;=====\\n= {target_letter} =\\n=====\\n\u0026quot;)\nstart = perf_counter() while True: if input() == target_letter: break else: print(\u0026ldquo;Nope! Try again.\u0026rdquo;) end = perf_counter()\nprint(f\u0026quot;You reacted in {(end - start) * 1000:.0f} milliseconds!\\nGoodbye!\u0026quot;)`\nNow the program will display a random character, and you need to press that exact character to have the game register your reaction time:\nWhat’s to be done? First, you’ll need to come to grips with using Popen() with basic commands, and then you’ll find another way to exploit the reaction game.\nUsing Popen() Using the Popen() constructor is very similar in appearance to using run(). If there’s an argument that you can pass to run(), then you’ll generally be able to pass it to Popen(). The fundamental difference is that it’s not a blocking call—rather than waiting until the process is finished, it’ll run the process in parallel. So you need to take this non-blocking nature into account if you want to read the new process’s output:\nPython\n`# popen_timer.py\nimport subprocess from time import sleep\nwith subprocess.Popen( [\u0026ldquo;python\u0026rdquo;, \u0026ldquo;timer.py\u0026rdquo;, \u0026ldquo;5\u0026rdquo;], stdout=subprocess.PIPE ) as process:\ndef poll_and_read(): print(f\u0026quot;Output from poll: {process.poll()}\u0026quot;) print(f\u0026quot;Output from stdout: {process.stdout.read1().decode('utf-8')}\u0026quot;) poll_and_read() sleep(3) poll_and_read() sleep(3) poll_and_read()` This program calls the timer process in a context manager and assigns stdout to a pipe. Then it runs the .poll() method on the Popen object and reads its stdout.\nThe .poll() method is a basic method to check if a process is still running. If it is, then .poll() returns None. Otherwise, it’ll return the process’s exit code.\nThen the program uses .read1() to try and read as many bytes as are available at .stdout.\nNote: If you put the Popen object into text mode and then called .read() on .stdout, the call to .read() would be blocking until it reached a newline. In this case, a newline would coincide with the end of the timer program. This behavior isn’t desired in this situation.\nTo read as many bytes as are available at that time, disregarding newlines, you need to read with .read1(). It’s important to note that .read1() is only available on byte streams, so you need to make sure to deal with encodings manually and not use text mode.\nThe output of this program first prints None because the process hasn’t yet finished. The program then prints what is available in stdout so far, which is the starting message and the first character of the animation.\nAfter three seconds, the timer hasn’t finished, so you get None again, along with two more characters of the animation. After another three seconds, the process has ended, so .poll() produces 0, and you get the final characters of the animation and Done!:\nText\nOutput from poll: None Output from stdout: Starting timer of 5 seconds . Output from poll: None Output from stdout: .. Output from poll: 0 Output from stdout: ..Done!\nIn this example, you’ve seen how the Popen() constructor works very differently from run(). In most cases, you don’t need this kind of fine-grained control. That said, in the next sections, you’ll see how you can pipe one process into another, and how you can hack the new reaction game.\nConnecting Two Processes Together With Pipes As mentioned in a previous section, if you need to connect processes together with pipes, you need to use the Popen() constructor. This is mainly because run() is a blocking call, so by the time the next process starts, the first one has ended, meaning that you can’t directly link up to its stdout.\nThis procedure will only be demonstrated for UNIX systems, because piping in Windows is far less common, as mentioned in the simulating a pipe section:\nPython\n`# popen_pipe.py\nimport subprocess\nls_process = subprocess.Popen([\u0026ldquo;ls\u0026rdquo;, \u0026ldquo;/usr/bin\u0026rdquo;], stdout=subprocess.PIPE) grep_process = subprocess.Popen( [\u0026ldquo;grep\u0026rdquo;, \u0026ldquo;python\u0026rdquo;], stdin=ls_process.stdout, stdout=subprocess.PIPE )\nfor line in grep_process.stdout: print(line.decode(\u0026ldquo;utf-8\u0026rdquo;).strip())`\nIn this example, the two processes are started in parallel. They are joined with a common pipe, and the for loop takes care of reading the pipe at stdout to output the lines.\nA key point to note is that in contrast to run(), which returns a CompletedProcess object, the Popen() constructor returns a Popen object. The standard stream attributes of a CompletedProcess point to bytes objects or strings, but the same attributes of a Popen object point to the actual streams. This allows you to communicate with processes as they’re running.\nWhether you really need to pipe processes into one another, though, is another matter. Ask yourself if there’s much to be lost by mediating the process with Python and using run() exclusively. There are some situations in which you really need Popen, though, such as hacking the new version of the reaction time game.\nInteracting Dynamically With a Process Now that you know you can use Popen() to interact with a process dynamically as it runs, it’s time to turn that knowledge toward exploiting the reaction time game again:\nPython\n`# reaction_game_v2_hack.py\nimport subprocess\ndef get_char(process): character = process.stdout.read1(1) print( character.decode(\u0026ldquo;utf-8\u0026rdquo;), end=\u0026quot;\u0026quot;, flush=True, # Unbuffered print ) return character.decode(\u0026ldquo;utf-8\u0026rdquo;)\ndef search_for_output(strings, process): buffer = \u0026quot;\u0026quot; while not any(string in buffer for string in strings): buffer = buffer + get_char(process)\nwith subprocess.Popen( [ \u0026ldquo;python\u0026rdquo;, \u0026ldquo;-u\u0026rdquo;, # Unbuffered stdout and stderr \u0026ldquo;reaction_game_v2.py\u0026rdquo;, ], stdin=subprocess.PIPE, stdout=subprocess.PIPE, ) as process: process.stdin.write(b\u0026quot;\\n\u0026quot;) process.stdin.flush() search_for_output([\u0026quot;==\\n= \u0026ldquo;, \u0026ldquo;==\\r\\n= \u0026ldquo;], process) target_char = get_char(process) stdout, stderr = process.communicate( input=f\u0026rdquo;{target_char}\\n\u0026rdquo;.encode(\u0026ldquo;utf-8\u0026rdquo;), timeout=10 ) print(stdout.decode(\u0026ldquo;utf-8\u0026rdquo;))`\nWith this script, you’re taking complete control of the buffering of a process, which is why you pass in arguments such as -u to the Python process and flush=True to print(). These arguments are to ensure that no extra buffering is taking place.\nThe script works by using a function that’ll search for one of a list of strings by grabbing one character at a time from the process’s stdout. As each character comes through, the script will search for the string.\nNote: To make this work on both Windows and UNIX-based systems, two strings are searched for: either \u0026quot;==\\n= \u0026quot; or \u0026quot;==\\r\\n= \u0026quot;. The Windows-style carriage return along with the typical newline is required on Windows systems.\nAfter the script has found one of the target strings, which in this case is the sequence of characters before the target letter, it’ll then grab the next character and write that letter to the process’s stdin followed by a newline:\nAt one millisecond, it’s not quite as good as the original hack, but it’s still very much superhuman. Well done!\nWith all this fun aside, interacting with processes using Popen can be very tricky and is prone to errors. First, see if you can use run() exclusively before resorting to the Popen() constructor.\nIf you really need to interact with processes at this level, the asyncio module has a high-level API to create and manage subprocesses.\nThe asyncio subprocess functionality is intended for more complex uses of subprocess where you may need to orchestrate various processes. This might be the case if you’re performing complex processing of many image, video, or audio files, for example. If you’re using subprocess at this level, then you’re probably building a library.\nConclusion You’ve completed your journey into the Python subprocess module. You should now be able to decide whether subprocess is a good fit for your problem. You should also be able to decide whether you need to invoke the shell. Aside from that, you should be able to run subprocesses and interact with their inputs and outputs.\nYou should also be able to start exploring the possibilities of process manipulation with the Popen() constructor.\nAlong the way, you’ve:\nLearned about processes in general Gone from basic to advanced usage of subprocess Understood how to raise and handle errors when using run() Gotten familiar with shells and their intricacies on both Windows and UNIX-like systems Explored the use cases for subprocess through practical examples Understood the standard I/O streams and how to interact with them Come to grips with pipes, both in the shell and with subprocess Looked at the Popen() constructor and used it for some advanced process communication You’re now ready to bring a variety of executables into your Pythonic sphere of influence!\nSTANDARD COMMANDS IN DJANGO INSTALLATION# python3 -m venv venv USEFUL PROPERTY AND METHOD IN DJANGO L\u0026rsquo;uso di Queryset Django querysets have several notable properties and methods that provide flexibility and ease of use when interacting with the database. Here are some key properties and methods of querysets:\nChaining:\nQuerysets are lazy, meaning they don\u0026rsquo;t hit the database until an action is performed. Multiple filters and operations can be chained together to build complex queries. Example:\npython Copy code queryset = Model.objects.filter(field1=value1).exclude(field2=value2).order_by(\u0026rsquo;-date_created\u0026rsquo;) Slicing:\nQuerysets can be sliced to retrieve a specific range of objects. Example:\npython Copy code queryset = Model.objects.all() result_slice = queryset[5:10] # Retrieve objects 5 through 9 Count:\nThe count method returns the number of objects in the queryset without fetching the actual objects. Example:\npython Copy code count = queryset.count() Distinct:\nThe distinct method eliminates duplicate rows from the queryset. Example:\npython Copy code distinct_values = Model.objects.values(\u0026lsquo;field\u0026rsquo;).distinct() Aggregate:\nThe aggregate method allows for the calculation of aggregate values (e.g., sum, average) on the queryset. Example:\npython Copy code from django.db.models import Avg average_value = Model.objects.aggregate(avg_value=Avg(\u0026rsquo;numeric_field\u0026rsquo;)) Values and ValuesList:\nThe values method returns a queryset of dictionaries representing the values of specific fields. The values_list method returns a queryset of tuples representing the values of specific fields. Example:\npython Copy code values_queryset = Model.objects.values(\u0026lsquo;field1\u0026rsquo;, \u0026lsquo;field2\u0026rsquo;) values_list_queryset = Model.objects.values_list(\u0026lsquo;field1\u0026rsquo;, \u0026lsquo;field2\u0026rsquo;) Exists:\nThe exists method checks if there are any records in the queryset. Example:\nqueryset_exists = Model.objects.filter(field=value).exists() Update and Delete:\nThe update method modifies multiple records in the database without fetching them. The delete method deletes records from the database without fetching them. Example:\npython Copy code Model.objects.filter(field=value).update(status=\u0026lsquo;new_status\u0026rsquo;) Model.objects.filter(field=value).delete() These are just a few of the many properties and methods provided by Django querysets. They offer a powerful and expressive way to interact with the database.\nEsempio in wagtail from datetime import datetime, timedelta, timezone from django.shortcuts import render from wagtail.core.models import Page from your_app.models import RoundPage # Replace \u0026lsquo;your_app\u0026rsquo; with the actual name of your app from path.to.get_deadline_date_for import get_deadline_date_for # Replace \u0026lsquo;path.to\u0026rsquo; with the actual path\ndef docs_internship(request): now = datetime.now(timezone.utc) today = get_deadline_date_for(now) five_weeks_ago = today - timedelta(days=7 * 5)\napplicant_round = RoundPage.objects.filter( pingnew__lte=today, internannounce__gt=today, ).first() intern_round = RoundPage.objects.filter( internannounce__lte=today, internends__gt=five_weeks_ago, ).first() return render(request, 'home/docs/internship_guide.html', { 'applicant_round': applicant_round, 'intern_round': intern_round, }) GIT \u0026amp; GITHUB Riferimenti Mastering MarkDown\nRicordarsi di aggiungere .gitgnore - git add .gitignore - git commit -m \u0026ldquo;Add .gitignore to exclude compiled Python files\u0026rdquo;\nPer effettuare il push da origine a remoto - git push origin implementazione-pagina\nSwitch to the New Branch: - git checkout new-branch-name\nCreare una nuova branch e posizionarsi sulla stessa - git checkout -b new-branch-name Il comando può essere visto come la sintesi dei due seguenti comandi: - git branch new-branch-name # Create a new branch - git checkout new-branch-name # Switch to the new branch\nYou\u0026rsquo;ve created a new branch (template-tutorial) without committing changes on your existing branch (implementazione-pagina) To address this, you\u0026rsquo;ll need to follow these steps to commit your changes on the implementazione-pagina branch and then switch back to the template-tutorial branch. Here\u0026rsquo;s a step-by-step guide:\nCommit Changes on implementazione-pagina: Assuming you are currently on the template-tutorial branch, ** switch back to the implementazione-pagina branch:** git checkout implementazione-pagina\nNow, add and commit your changes:\ngit add . git commit -m \u0026quot;Your commit message here\u0026quot;\nPush Changes to Remote (implementazione-pagina): Assuming the remote branch is named implementazione-pagina: git push origin implementazione-pagina\n** Switch Back to template-tutorial:** Now, switch back to the template-tutorial branch: git checkout template-tutorial\n*** If you haven\u0026rsquo;t pushed the template-tutorial branch yet, you can push it to the remote repository when you\u0026rsquo;re ready:***\ngit push origin template-tutorial\n*** How can see from my vsc local if a git branch is present also in the remote github? ***\ngit fetch --all git branch -a This fetches all branches from the remote repository and lists both local and remote branches. Remote branches are prefixed with \u0026ldquo;remotes/origin/\u0026rdquo;. Check if your branch is listed among the remotes.\n*** Come posso creare una nuova branch in local, e poi crearla anche in Github, poi effettuare il push e rendere questa branch principale? ***\nCreate a new branch locally and switch to it (chimiamo la nuova branch template-tutorial): git checkout -b template-tutorial\nPush the new branch to GitHub - *** If you want to make sure that the new branch on GitHub exactly matches your local branch, you can use the -u (or \u0026ndash;set-upstream) option when pushing for the first time ***\ngit push -u origin template-tutorial\nSet the upstream for the new branch:\ngit branch --set-upstream-to=origin/template-tutorial template-tutorial![alt]( \u0026lsquo;{\u0026ldquo;class\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;title\u0026rdquo;: \u0026ldquo;\u0026rdquo;}\u0026rsquo;)\nNow, further pushes can be simplified to:\ngit push\nTo revert the changes and go back to the original commit before the changes, you can use the following commands: git reset --hard HEAD git clean -fd\nThe first command (git reset \u0026ndash;hard HEAD) resets your branch to the latest commit, discarding changes. The second command (git clean -fd) removes untracked files and directories. Use them with caution, as they are not reversible.\n-fd stands for what? In the context of the git clean command:\n-f stands for force. -d stands for directory. Together, -fd means force removal of untracked directories. This option is used to remove untracked files and directories forcefully.\ndelete a local branch and also delete it on the remote repository on GitHub Delete the local branch:\ngit branch -d branch_name![alt]( \u0026lsquo;{\u0026ldquo;class\u0026rdquo;: \u0026ldquo;\u0026rdquo;, \u0026ldquo;title\u0026rdquo;: \u0026ldquo;\u0026rdquo;}\u0026rsquo;)\nReplace branch_name with the name of the branch you want to delete.\nIf the branch contains unmerged changes, you might need to force delete it:\ngit branch -D branch_name\nDelete the remote branch:\ngit push origin --delete branch_name\nThis will delete the branch on the remote repository (GitHub).\nUpdate your local repository to reflect the changes on the remote:\ngit fetch --prune\nThe \u0026ndash;prune flag removes any remote tracking branches that no longer exist on the remote.\nI want to synch another an oldest branch named \u0026ldquo;template-tutorial\u0026rdquo; with a newest branch named template-sheetlike and after delete this last one (template-sheetlike) Switch to the template-tutorial branch: git switch template-tutorial\nRebase template-sheetlike onto template-tutorial: git rebase template-sheetlike\nPush the changes to the remote repository: git push origin template-tutorial --force Note: Force-pushing after a rebase rewrites the commit history. Use it with caution, especially if the branch has already been shared with others\nDelete the template-sheetlike branch: git branch -d template-sheetlike git push origin --delete template-sheetlike\nsome useful notes Merge: Creates Merge Commits: When you merge one branch into another, Git creates a new merge commit that has two parent commits: one from the branch you\u0026rsquo;re merging and another from the branch you\u0026rsquo;re merging into. This results in a non-linear history with multiple branches merging into each other Preserves Original History:\nThe original commits from both branches remain unchanged. This approach keeps a clear record of when changes were made on each branch.\nRebase: Linearizes History:\nRebase is used to linearize the commit history. It moves or combines a sequence of commits to a new base commit. When you rebase one branch onto another, it effectively transplants the entire branch onto the tip of the other branch, creating a linear history. No Merge Commits:\nUnlike merge, rebase doesn\u0026rsquo;t create additional merge commits. It can result in a cleaner, more linear history. When to Choose Each Approach:\nMerge: Use merge when you want to preserve the original commit history, especially when collaborating with others. Good for feature branches and when you want to maintain a clear record of branch integration points. Rebase:\nUse rebase when you want a clean, linear history and don\u0026rsquo;t mind rewriting commits. Useful for feature branches before merging into a shared branch to avoid unnecessary merge commits. Switch vs. Checkout: git switch is a more modern and user-friendly command introduced in recent versions of Git. It is designed specifically for branch switching. If you\u0026rsquo;re using a version of Git that supports git switch, you can replace git checkout with git switch:\nSwitching Branch: git switch template-tutorial Both commands essentially do the same thing in this context, but git switch provides a clearer and more explicit syntax for branch-related operations. If your Git version supports it, feel free to use git switch instead of git checkout.\nYAML PROTOCOL YAML (YAML Ain\u0026rsquo;t Markup Language) is a human-readable data serialization format that is often used for configuration files and data exchange between languages with different data structures. In a YAML file, indentation is crucial, as it determines the structure of the data. Here are some details on writing YAML files:\n1. Indentation: YAML uses indentation to represent the structure of the data. Spaces are recommended for indentation (not tabs), and the number of spaces is significant. Typically, two spaces or four spaces are used for each level of indentation. codekey1: key2: value key3: - item1 - item2 ### 2. **Key-Value Pairs:** - YAML uses a simple key-value format. Keys and values are separated by a colon, and the key-value pair is represented on a new line. ```yaml codename: John Doe age: 30 3. Lists: Lists are represented using a hyphen followed by a space (- ). Lists can contain any combination of values, and each item is indented under the list key. codefruits: - apple - banana - orange 4. Dictionaries (Mappings): Dictionaries or mappings are represented using key-value pairs, and the key-value pairs are indented under the dictionary key. name: John Doe age: 30 5. Strings: Strings can be written without quotes. However, quotes are used when a string contains special characters or reserved words. message: Hello, World! 6. Multiline Strings: Multiline strings can be represented using the | or \u0026gt; characters. The | preserves newlines, while \u0026gt; folds newlines. codemultiline: | This is a multiline string in YAML. 7. Comments: Comments start with the # character and continue to the end of the line. code# This is a comment key: value 8. Anchors and Aliases: YAML supports anchors (\u0026amp;) and aliases (*) for creating references to the same data in multiple places. codefirst: \u0026amp;anchor_name John Doe second: *anchor_name These are some basic conventions for writing YAML files. Ensure that you are consistent with indentation, use proper syntax for key-value pairs, lists, and dictionaries, and pay attention to the structure of your YAML documents. Many programming languages and tools use YAML, and understanding its syntax is beneficial for working with various configurations and data files.\nWAGTAIL How to use StreamField for mixed content StreamField block reference Templating - Jinja Wrinting Templates La regola da seguire è questa:\ncode: class wagtail.fields.StreamField(blocks, use_json_field=None, blank=False, min_num=None, max_num=None, block_counts=None, collapsed=False)\nE questa la spiegazione:\nclass wagtail.fields.StreamField: This line defines a class named StreamField in the wagtail.fields module.\n(blocks, use_json_field=None, blank=False, min_num=None, max_num=None, block_counts=None, collapsed=False): These are the parameters that the StreamField class constructor (init method) accepts. Let\u0026rsquo;s go through each one:\nblocks: This is a required parameter. It represents the blocks that can be used in the stream. It seems like it should be provided when creating an instance of StreamField.\nuse_json_field=None: This is an optional parameter with a default value of None. It allows you to specify whether to use a JSON field for storage. If not provided, it defaults to None.\nblank=False: This is an optional parameter with a default value of False. It indicates whether the field is allowed to be blank when used in a form. If not provided, it defaults to False.\nmin_num=None: This is an optional parameter with a default value of None. It specifies the minimum number of blocks required. If not provided, it defaults to None.\nmax_num=None: This is an optional parameter with a default value of None. It specifies the maximum number of blocks allowed. If not provided, it defaults to None.\nblock_counts=None: This is an optional parameter with a default value of None. It seems related to counting blocks. If not provided, it defaults to None.\ncollapsed=False: This is an optional parameter with a default value of False. It indicates whether the blocks should be collapsed in the Wagtail admin interface. If not provided, it defaults to False\nCosì ad esempio per questo codice. Possiamo effettuare il breakdown di questo codice in base alla regola definita:\n`class BlogPage(Page): author = models.CharField(max_length=255, default=\u0026lsquo;Default Author\u0026rsquo;) date = models.DateField(\u0026ldquo;Post date\u0026rdquo;)\nbody = StreamField( [ ('heading', blocks.CharBlock(form_classname=\u0026quot;title\u0026quot;)), ('paragraph', blocks.RichTextBlock()), ('image', ImageChooserBlock()), ('code', CodeBlock()), ('raw_html', RawHTMLBlock()), ], use_json_field=True ) content_panels = Page.content_panels + [ FieldPanel('author'), FieldPanel('date'), FieldPanel('body'), ] `\nauthor = models.CharField(max_length=255, default=\u0026lsquo;Default Author\u0026rsquo;): This line defines a character field named author in the BlogPage class. It has a maximum length of 255 characters and a default value of \u0026lsquo;Default Author\u0026rsquo;.\ndate = models.DateField(\u0026ldquo;Post date\u0026rdquo;): This line defines a date field named date in the BlogPage class with a human-readable name \u0026ldquo;Post date\u0026rdquo;.\nbody = StreamField([\u0026hellip;], use_json_field=True): This line defines a stream field named body in the BlogPage class. It allows the inclusion of different block types, such as CharBlock, RichTextBlock, ImageChooserBlock, CodeBlock, and RawHTMLBlock. The use_json_field parameter is set to True, indicating that a JSON field will be used for storage.\ncontent_panels = Page.content_panels + [\u0026hellip;]: This line defines the content panels for the Wagtail admin interface. It includes panels for \u0026lsquo;author\u0026rsquo;, \u0026lsquo;date\u0026rsquo;, and \u0026lsquo;body\u0026rsquo;.\nPoi in particolare:\ncontent_panels definition in the BlogPage class:#### content_panels = Page.content_panels + [ FieldPanel('author'), FieldPanel('date'), FieldPanel('body'), ]\nPage.content_panels: This part includes the content panels defined in the parent Page class. It allows the inclusion of standard page fields, such as title, slug, publish date, etc.\nFieldPanel(\u0026lsquo;author\u0026rsquo;): This adds a panel for the author field to the content panels. It\u0026rsquo;s likely a simple text input for the author\u0026rsquo;s name.\nFieldPanel(\u0026lsquo;date\u0026rsquo;): This adds a panel for the date field, probably a date picker for selecting the post date.\nFieldPanel(\u0026lsquo;body\u0026rsquo;): This adds a panel for the body field. Since it\u0026rsquo;s a StreamField, it might include a dynamic set of blocks like headings, paragraphs, images, code blocks, and raw HTML.\nUso dello StructBox in Wagtail Example Model with StructBlock Consider a simple model for a page with a StreamField containing a StructBlock named \u0026lsquo;person\u0026rsquo;:\n` # models.py from django.db import models from wagtail.core.fields import StreamField from wagtail.core import blocks from wagtail.images.blocks import ImageChooserBlock from wagtail.core.models import Page from wagtail.admin.edit_handlers import FieldPanel, StreamFieldPanel\nclass BlogPage(Page): body = StreamField([ (\u0026lsquo;person\u0026rsquo;, blocks.StructBlock([ (\u0026lsquo;first_name\u0026rsquo;, blocks.CharBlock()), (\u0026lsquo;surname\u0026rsquo;, blocks.CharBlock()), (\u0026lsquo;photo\u0026rsquo;, ImageChooserBlock(required=False)), (\u0026lsquo;biography\u0026rsquo;, blocks.RichTextBlock()), ])), (\u0026lsquo;heading\u0026rsquo;, blocks.CharBlock(form_classname=\u0026ldquo;title\u0026rdquo;)), (\u0026lsquo;paragraph\u0026rsquo;, blocks.RichTextBlock()), (\u0026lsquo;image\u0026rsquo;, ImageChooserBlock()), ], use_json_field=True)\ncontent_panels = Page.content_panels + [ StreamFieldPanel('body'), ] `\u0026lt;/span\u0026gt; Diagram Explanation Blog Page with StreamField and StructBlock:\nA BlogPage contains a StreamField named \u0026lsquo;body\u0026rsquo;. \u0026lsquo;body\u0026rsquo; includes various block types, one of which is a StructBlock named \u0026lsquo;person\u0026rsquo;. Person StructBlock:\nThe \u0026lsquo;person\u0026rsquo; block is a StructBlock containing fields like \u0026lsquo;first_name\u0026rsquo;, \u0026lsquo;surname\u0026rsquo;, \u0026lsquo;photo\u0026rsquo;, and \u0026lsquo;biography\u0026rsquo;. Block Instances:\nWhen editing a BlogPage, you can add multiple instances of different block types, including \u0026lsquo;person\u0026rsquo;. Each \u0026lsquo;person\u0026rsquo; block instance can have its own \u0026lsquo;first_name\u0026rsquo;, \u0026lsquo;surname\u0026rsquo;, \u0026lsquo;photo\u0026rsquo;, and \u0026lsquo;biography\u0026rsquo;\nTemplate Implementation\nTo render this in a template, you can use the following:\n`\u0026lt;!-- templates/blog_page.html --\u0026gt; {% extends \u0026#34;base.html\u0026#34; %} {% block content %} \u0026lt;article\u0026gt; {% for block in page.body %} {% if block.block_type == \u0026#39;person\u0026#39; %} \u0026lt;div class=\u0026#34;person\u0026#34;\u0026gt; {% if block.value.photo %} {% image block.value.photo width-400 %} {% endif %} \u0026lt;h2\u0026gt;{{ block.value.first_name }} {{ block.value.surname }}\u0026lt;/h2\u0026gt; {{ block.value.biography }} \u0026lt;/div\u0026gt; {% else %} {# Rendering for other block types #} \u0026lt;section class=\u0026#34;{{ block.block_type }}\u0026#34;\u0026gt; {% include_block block %} \u0026lt;/section\u0026gt; {% endif %} {% endfor %} \u0026lt;/article\u0026gt; {% endblock %} Database Initialization\nWhen you run makemigrations and migrate after adding the StructBlock to your model, the necessary database tables and fields are created. The use_json_field=True parameter in the StreamField indicates that the data for the StreamField will be stored as JSON in the database.\nHere\u0026rsquo;s how you perform the migration:\nbash Copy code python manage.py makemigrations python manage.py migrate After migration, you can create or edit a BlogPage instance through the Wagtail admin interface. The StructBlock fields will be part of the form for each \u0026lsquo;person\u0026rsquo; block within the \u0026lsquo;body\u0026rsquo; StreamField.\nRiferimenti Rapidi Wagtail Caso Studio web page\nHow to use Streamfield for mixed content\nStreamFieldBlock Reference\nCaratteristiche avanzate di Diango - Wagtail Uno dei porblemi che si incontrano effettuando delle tabelle all\u0026rsquo;interno di wagtail ma in generale anche in Django è il caso pratico della renderizzazione degli headers di una tabella se si vogliono recuperare ad esempio i dati all\u0026rsquo;interno delle celle della tabella.\nAttenzione!: questo progetto è illustrato al solo fine didattico. Infatti nell\u0026rsquo;applicazione concreta vi sono notevoli problemi nell\u0026rsquo;effettuare il passaggio dei dati da Django a Wagtail. Per cui ai fini applicativi la via migliore per rendere i dati da Django a Wagtail è quella della costruzione di un API attraverso serializer (vedere capitolo)\nQuesto codice di esempio effettua il debug su ciò che è successo:\n` {% for column in block.value.columns %} {{ column.header|default:\u0026ldquo;Column Header\u0026rdquo; }}\n\u0026lt;!-- Debugging statements --\u0026gt; \u0026lt;p\u0026gt;block.value.rows: {{ block.value.rows|list }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;block.value.rows.1: {{ block.value.rows|list.1|default:\u0026quot;\u0026quot; }}\u0026lt;/p\u0026gt; {% with block.value.rows|list.1|default:\u0026quot;\u0026quot; as row_values %} {{ row_values.0|default:\u0026quot;\u0026quot; }} {% endwith %} \u0026lt;/th\u0026gt; {% endfor %} \u0026lt;/tr\u0026gt; \u0026lt;th\u0026gt; Column Header \u0026lt;!-- Debugging statements --\u0026gt; \u0026lt;p\u0026gt;block.value.rows: \u0026amp;lt;generator object TypedTable.rows at 0x7f08958de2e0\u0026amp;gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;block.value.rows.1: \u0026lt;/p\u0026gt; ` Approfondendo la ricerca si artriva a tale indicazione :::caution The issue seems to be related to the fact that block.value.rows is a generator object. In Python, generators are lazy and can be consumed only once. If you try to iterate through the generator more than once, you will get an empty result on subsequent iterations.\nIn your case, it seems like the generator has been consumed once, which is why when you try to access block.value.rows.1, it doesn\u0026rsquo;t contain any values.\nTo address this issue, you might want to convert the generator to a list so that you can iterate through it multiple times. However, since you are using the TypedTableBlock from wagtail.contrib.typed_table_block, you might need to adjust how you access the rows.\nHere is a modification that converts the generator to a list before using it:\ndjango Copy code\n\u0026lt;!-- Debugging statements --\u0026gt; \u0026lt;p\u0026gt;block.value.rows: {{ block.value.rows|list }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;block.value.rows.1: {{ block.value.rows|list.1|default:\u0026quot;\u0026quot; }}\u0026lt;/p\u0026gt; {% with block.value.rows|list.1|default:\u0026quot;\u0026quot; as row_values %} {{ row_values.0|default:\u0026quot;\u0026quot; }} {% endwith %} \u0026lt;/th\u0026gt; {% endfor %} \u0026lt;/tr\u0026gt; HOW TO FEED A TABLE FROM DJANGO ADMIN PANEL, OPEN IN AS BLOCK INTO WAGTAIL ADMIN PANEL AND RENDER IT INTO THE WAGTAIL FRONTEND Premessa: prima di effettuare questa complessa operazione va tenuto in conto che i due progetti uno django e l\u0026rsquo;altro wagtail derivano da due repository differenti. Quindi il problema iniziale sarà quello di renedere omogenei i file .git. Per fare ciò dunque di seguito si descrive il metodo migliore individuato:\nIf you want to consolidate both the Django and Wagtail projects into a single Git repository, and you\u0026rsquo;ve already initialized separate repositories in each project\u0026rsquo;s directory, you have a couple of options:\nOption 1: Delete Existing Git Repositories\nDelete Git repositories in directory and subdirectories:\nNavigate to each subdirectory (e.g., django_general_template2 and blog_wiki_wag/blog_page_wiki_wag/wiki-wag) containing a Git repository. Run rm -rf .git to delete the existing Git repository. Initialize a new Git repository in the root directory:\nRun cd /path/to/django_general_template2 (replace /path/to/django_general_template2 with your actual path). Run git init to initialize a new Git repository. Add, commit, and push:\nAdd all files with git add .. Commit the changes with git commit -m \u0026quot;Initial commit\u0026quot;. If you\u0026rsquo;ve already set up a remote repository, push the changes to it. Great! Since you\u0026rsquo;ve deleted the existing Git repositories and initialized a new one in the root directory, here are the steps to create a new GitHub repository (django-wiki-wag) and push your local changes to it:\nCreate a New GitHub Repository:\nGo to GitHub. Log in to your account. Click the \u0026ldquo;+\u0026rdquo; icon in the top right corner and select \u0026ldquo;New repository.\u0026rdquo; Fill in the repository name (e.g., django-wiki-wag), add a description if you want, and choose other repository settings. Click \u0026ldquo;Create repository.\u0026rdquo; Set the Remote Origin for Your Local Repository:\nIn your local terminal, navigate to the root directory of your project.\nRun the following commands, replacing the repository URL with your newly created repository URL:\nbashCopy code git remote add origin https://github.com/your-username/django-wiki-wag.git Add, Commit, and Push:\nRun the following commands to add all files, commit your changes, and push to GitHub:\nbashCopy codegit add . git commit -m \u0026#34;Initial commit\u0026#34; git push -u origin main Note: Replace main with the name of the branch you are working on (it could be master or another branch).\nVerify on GitHub:\nVisit your GitHub repository (https://github.com/your-username/django-wiki-wag). Confirm that your files and project structure are visible. Now, your local project should be synchronized with the new GitHub repository. If you encounter any issues during the process, feel free to ask for further assistance!\nTo achieve your goal, you\u0026rsquo;ll need to follow a series of steps. I\u0026rsquo;ll provide you with a step-by-step guide to make the necessary changes and additions to your Django admin, Wagtail models, and HTML template.\nStep 1: Adjust Wagtail Settings\nIn the settings.py of your Wagtail project (wiki-wag), ensure that the ALLOWED_HOSTS setting includes the appropriate values for your Django project. Update other settings if needed.\npythonCopy code# wiki-wag/settings/base.py ALLOWED_HOSTS = [\u0026#39;yourdjangoapp.com\u0026#39;, \u0026#39;localhost\u0026#39;, \u0026#39;127.0.0.1\u0026#39;] Step 2: Add Wagtail settings to Django settings.py\nIn your Django project (`general_template 1), include the Wagtail settings by updating settings.py:\n\u0026#34;\u0026#34;\u0026#34; Django settings for general_template1 project. Generated by \u0026#39;django-admin startproject\u0026#39; using Django 4.2.2. For more information on this file, see https://docs.djangoproject.com/en/4.2/topics/settings/ For the full list of settings and their values, see https://docs.djangoproject.com/en/4.2/ref/settings/ \u0026#34;\u0026#34;\u0026#34; from pathlib import Path # Build paths inside the project like this: BASE_DIR / \u0026#39;subdir\u0026#39;. BASE_DIR = Path(__file__).resolve().parent.parent # Quick-start development settings - unsuitable for production # See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/ # SECURITY WARNING: keep the secret key used in production secret! SECRET_KEY = \u0026#39;django-insecure-2-yc!0z!mcv#w$3vk6#s5i635l+bg#x3+24w2!26ikg4o-dj4u\u0026#39; # SECURITY WARNING: don\u0026#39;t run with debug turned on in production! DEBUG = True # ALLOWED_HOSTS = [\u0026#39;127.0.0.1\u0026#39;, \u0026#39;localhost\u0026#39;, \u0026#39;146.190.169.21\u0026#39;] # tiene conto delle attività su droplet ALLOWED_HOSTS = [\u0026#39;app.sgbh.org\u0026#39;, \u0026#39;www.sgbh.org\u0026#39;, \u0026#39;127.0.0.1\u0026#39;, \u0026#39;localhost\u0026#39;, \u0026#39;146.190.169.21\u0026#39;] SECURE_PROXY_SSL_HEADER = (\u0026#39;HTTP_X_FORWARDED_PROTO\u0026#39;, \u0026#39;https\u0026#39;) # Application definition INSTALLED_APPS = [ \u0026#39;wagtail.contrib.forms\u0026#39;, \u0026#39;wagtail.contrib.redirects\u0026#39;, \u0026#39;wagtail.embeds\u0026#39;, \u0026#39;wagtail.sites\u0026#39;, \u0026#39;wagtail.users\u0026#39;, \u0026#39;wagtail.snippets\u0026#39;, \u0026#39;wagtail.documents\u0026#39;, \u0026#39;wagtail.images\u0026#39;, \u0026#39;wagtail.search\u0026#39;, \u0026#39;wagtail.admin\u0026#39;, \u0026#39;taggit\u0026#39;, \u0026#39;modelcluster\u0026#39;, \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;sgq\u0026#39;, \u0026#39;wagtail\u0026#39;, ] MIDDLEWARE = [ \u0026#39;django.middleware.security.SecurityMiddleware\u0026#39;, \u0026#39;django.contrib.sessions.middleware.SessionMiddleware\u0026#39;, \u0026#39;django.middleware.common.CommonMiddleware\u0026#39;, \u0026#39;django.middleware.csrf.CsrfViewMiddleware\u0026#39;, \u0026#39;django.contrib.auth.middleware.AuthenticationMiddleware\u0026#39;, \u0026#39;django.contrib.messages.middleware.MessageMiddleware\u0026#39;, \u0026#39;django.middleware.clickjacking.XFrameOptionsMiddleware\u0026#39;, \u0026#39;wagtail.contrib.redirects.middleware.RedirectMiddleware\u0026#39;, ] ROOT_URLCONF = \u0026#39;general_template1.urls\u0026#39; TEMPLATES = [ { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.template.backends.django.DjangoTemplates\u0026#39;, \u0026#39;DIRS\u0026#39;: [], \u0026#39;APP_DIRS\u0026#39;: True, \u0026#39;OPTIONS\u0026#39;: { \u0026#39;context_processors\u0026#39;: [ \u0026#39;django.template.context_processors.debug\u0026#39;, \u0026#39;django.template.context_processors.request\u0026#39;, \u0026#39;django.contrib.auth.context_processors.auth\u0026#39;, \u0026#39;django.contrib.messages.context_processors.messages\u0026#39;, ], }, }, ] WSGI_APPLICATION = \u0026#39;general_template1.wsgi.application\u0026#39; WSGI_SERVER_PORT = 443 # Database # https://docs.djangoproject.com/en/4.2/ref/settings/#databases DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.sqlite3\u0026#39;, \u0026#39;NAME\u0026#39;: BASE_DIR / \u0026#39;db.sqlite3\u0026#39;, } } # Password validation # https://docs.djangoproject.com/en/4.2/ref/settings/#auth-password-validators AUTH_PASSWORD_VALIDATORS = [ { \u0026#39;NAME\u0026#39;: \u0026#39;django.contrib.auth.password_validation.UserAttributeSimilarityValidator\u0026#39;, }, { \u0026#39;NAME\u0026#39;: \u0026#39;django.contrib.auth.password_validation.MinimumLengthValidator\u0026#39;, }, { \u0026#39;NAME\u0026#39;: \u0026#39;django.contrib.auth.password_validation.CommonPasswordValidator\u0026#39;, }, { \u0026#39;NAME\u0026#39;: \u0026#39;django.contrib.auth.password_validation.NumericPasswordValidator\u0026#39;, }, ] # Internationalization # https://docs.djangoproject.com/en/4.2/topics/i18n/ LANGUAGE_CODE = \u0026#39;en-us\u0026#39; TIME_ZONE = \u0026#39;UTC\u0026#39; USE_I18N = True USE_TZ = True # Static files (CSS, JavaScript, Images) # https://docs.djangoproject.com/en/4.2/howto/static-files/ STATIC_URL = \u0026#39;static/\u0026#39; # Default primary key field type # https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field DEFAULT_AUTO_FIELD = \u0026#39;django.db.models.BigAutoField\u0026#39; Step 3: Add Wagtail URLs to Django URLs\nIn your Django project (`general_template 1), include the Wagtail urls by updating urls.py:\nfrom django.contrib import admin from django.urls import path, include from wagtail import urls as wagtail_urls urlpatterns = [ path(\u0026#39;\u0026#39;, include(\u0026#39;sgq.urls\u0026#39;)), # Include the app-level URLs path(\u0026#39;admin/\u0026#39;, admin.site.urls), # path(\u0026#39;wagtail/\u0026#39;, include(\u0026#39;wagtail.core.urls\u0026#39;)), # nuovo inserimento path(\u0026#39;wagtail/\u0026#39;, include(wagtail_urls)), # nuovo inserimento ] **Step 4: Add a Fixed Table Block to Your Models **and Update BlogPage Model ** In your blog/models.py, add the FixedTableBlock to the list of available blocks. This block will represent the fixed table content. Include the FixedTableBlock in the StreamField of your BlogPage model.\nThe key changes here are adding the import for FixedTableBlock and including it in the StreamField under the name 'fixed_table'. from wagtail.images.blocks import ImageChooserBlock from wagtail.fields import StreamField, RichTextField from wagtail.admin.panels import FieldPanel from wagtail.documents.blocks import DocumentChooserBlock from wagtail.models import Page from wagtail import blocks from wagtail.contrib.table_block.blocks import TableBlock from wagtail.contrib.routable_page.models import RoutablePageMixin, path from django.db import models from wagtail.search import index from modelcluster.fields import ParentalKey from wagtail.contrib.forms.models import AbstractEmailForm, AbstractFormField from .blocks import PublicationBlock # rif 1 - Adding in rendering get_absolute_url from wagtail.contrib.typed_table_block.blocks import TypedTableBlock from wagtail.images.blocks import ImageChooserBlock class RawHTMLBlock(blocks.RawHTMLBlock): class Meta: icon = \u0026#34;code\u0026#34; # Set a suitable icon from available Wagtail icons template = \u0026#39;blog/raw_html_block.html\u0026#39; class CodeBlock(blocks.StructBlock): code = blocks.TextBlock() class Meta: template = \u0026#39;blog/code_block.html\u0026#39; class FixedTableBlock(blocks.StructBlock): fixed_table_text = blocks.CharBlock() class Meta: icon = \u0026#39;table\u0026#39; # Set an icon for the block template = \u0026#39;blog/fixed_table_block.html\u0026#39; # Create this template for rendering the block class BlogPage(Page): author = models.CharField(max_length=255, default=\u0026#39;Default Author\u0026#39;) date = models.DateField(\u0026#34;Post date\u0026#34;) # New field for content choice content_choice = models.CharField( max_length=20, choices=[ (\u0026#39;choice_one\u0026#39;, \u0026#39;Choice One\u0026#39;), (\u0026#39;choice_two\u0026#39;, \u0026#39;Choice Two\u0026#39;), ], default=\u0026#39;choice_one\u0026#39;, # Set a default choice help_text=\u0026#34;Select the content to be displayed on the page.\u0026#34; ) body = StreamField([ (\u0026#39;heading\u0026#39;, blocks.CharBlock(form_classname=\u0026#34;title\u0026#34;)), (\u0026#39;paragraph\u0026#39;, blocks.RichTextBlock()), (\u0026#39;image\u0026#39;, ImageChooserBlock()), (\u0026#39;code\u0026#39;, CodeBlock()), (\u0026#39;raw_html\u0026#39;, RawHTMLBlock()), (\u0026#39;publication\u0026#39;, PublicationBlock()), # rif 1 - Adding in rendering get_absolute_url (\u0026#39;table\u0026#39;, TypedTableBlock([ (\u0026#39;text\u0026#39;, blocks.CharBlock()), (\u0026#39;numeric\u0026#39;, blocks.FloatBlock()), (\u0026#39;rich_text\u0026#39;, blocks.RichTextBlock()), (\u0026#39;image\u0026#39;, ImageChooserBlock()), (\u0026#39;country\u0026#39;, blocks.ChoiceBlock(choices=[ (\u0026#39;be\u0026#39;, \u0026#39;Belgium\u0026#39;), (\u0026#39;fr\u0026#39;, \u0026#39;France\u0026#39;), (\u0026#39;de\u0026#39;, \u0026#39;Germany\u0026#39;), (\u0026#39;nl\u0026#39;, \u0026#39;Netherlands\u0026#39;), (\u0026#39;pl\u0026#39;, \u0026#39;Poland\u0026#39;), (\u0026#39;uk\u0026#39;, \u0026#39;United Kingdom\u0026#39;), ])), ])), (\u0026#39;fixed_table\u0026#39;, FixedTableBlock()), # Add the FixedTableBlock ], use_json_field=True) content_panels = Page.content_panels + [ FieldPanel(\u0026#39;author\u0026#39;), FieldPanel(\u0026#39;date\u0026#39;), FieldPanel(\u0026#39;content_choice\u0026#39;), FieldPanel(\u0026#39;body\u0026#39;), ] **Step 5: **Go in the Wagtail manage.py level and make sure to run migrations after making these changes:\npython3 manage.py makemigrations python3 manage.py migrate Now you can use the Wagtail admin to add and edit the content for the fixed_table block in your BlogPage. This content should then be rendered in your blog_page.html\nAt this stage you go into Wagtail Project via **python3 manage.py runserver ** into admin panel and if all works you can access and add the table. In the wagtail preview mode you receive a visualization error because the blog/fixed_table_block.html does not exists!\nStep 6 - Creation of blog/fixed_table_block.html\nSo before to jump to Django admin level to create an input data entry let\u0026rsquo;s try to enter the data from FixedTableBlock(). In this manner sure that all is working fine just until now. To do this First, update the FixedTableBlock in models.py:\npythonCopy codefrom wagtail.core import blocks class FixedTableBlock(blocks.StructBlock): nation = blocks.CharBlock(required=True, help_text=\u0026#39;Enter nation\u0026#39;) capital = blocks.CharBlock(required=True, help_text=\u0026#39;Enter capital\u0026#39;) class Meta: template = \u0026#39;blog/fixed_table_block.html\u0026#39; Then, create or update the template file at blog/templates/blog/fixed_table_block.html:\nhtmlCopy code\u0026lt;div\u0026gt; \u0026lt;table class=\u0026#34;table table-bordered table-striped\u0026#34;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Nation\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Capital\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;{{ value.nation }}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{ value.capital }}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; Go in the Wagtail manage.py level and make sure to run migrations after making these changes:\npython3 manage.py makemigrations python3 manage.py migrate python3 manage.py migrate If all works you are able to input the data and see the table in Wagtail preview mode\nAlways remeber to conslidate you commmit pushing on Github\nStep 7 - Implementation models.py - Django side\nCreate a Django model for the content you want to manage:\nDefine a Django model in your models.py that represents the content you want to associate with the FixedTableBlock\npythonCopy code# models.py from django.db import models class FixedTableContent(models.Model): nation = models.CharField(max_length=255) capital = models.CharField(max_length=255) def __str__(self): return self.nation Step 8 - Implementation admin.py - Django side\nCreate an admin class for the new model:\nCreate an admin class for your new model in the admin.py file:\n# admin.py from django.contrib import admin from .models import FixedTableContent @admin.register(FixedTableContent) class FixedTableContentAdmin(admin.ModelAdmin): list_display = (\u0026#39;nation\u0026#39;, \u0026#39;capital\u0026#39;) This admin class will allow you to manage instances of FixedTableContent in the Django admin.\n\u0026mdash;\u0026mdash;\u0026mdash; FINO A QUI \u0026ndash;\ntemplate.Step 3: Create Template for FixedTableBlock Create a template file at blog/templates/blog/fixed_table_block.html for rendering the FixedTableBlock. This template will be used to display the fixed table content.\nhtml Copy code {{ value.fixed_table_text }} Step 4: Run Migrations Run the following commands to apply the model changes:\nbash Copy code python manage.py makemigrations python manage.py migrate Step 5: Update Django Admin Create an admin class for BlogPage in blog/wagtail_hooks.py:\npython Copy code from wagtail.contrib.modeladmin.options import ( ModelAdmin, modeladmin_register, ModelAdminGroup ) from .models import BlogPage\nclass BlogPageAdmin(ModelAdmin): model = BlogPage menu_label = \u0026lsquo;Blog Pages\u0026rsquo; menu_icon = \u0026lsquo;doc-full-inverse\u0026rsquo; menu_order = 200 add_to_settings_menu = False exclude_from_explorer = False list_display = (\u0026rsquo;title\u0026rsquo;, \u0026lsquo;author\u0026rsquo;, \u0026lsquo;date\u0026rsquo;, \u0026lsquo;content_choice\u0026rsquo;) search_fields = (\u0026rsquo;title\u0026rsquo;, \u0026lsquo;author\u0026rsquo;, \u0026lsquo;date\u0026rsquo;, \u0026lsquo;content_choice\u0026rsquo;)\nmodeladmin_register(BlogPageAdmin) Step 6: Include Admin CSS In your blog/static/css/admin.css file, add the following CSS to improve the display of the custom block in the admin.\ncss Copy code .wagtail-edit-handler-fixed_table .field-content textarea { height: 100px; /* Adjust the height as needed */ } Step 7: Update BlogPage Admin Panels Update the content_panels in BlogPage to include the new block:\npython Copy code\n\u0026hellip; class BlogPage(Page): # \u0026hellip;\ncontent_panels = Page.content_panels + [ FieldPanel('author'), FieldPanel('date'), FieldPanel('content_choice'), FieldPanel('body'), ] Step 8: Update blog_page.html Update blog/templates/blog/blog_page.html to render the new FixedTableBlock.\nhtml Copy code\n{% for block in page.body %} {% if block.block_type == \u0026lsquo;fixed_table\u0026rsquo; %} {% include_block block %} {% elif block.block_type == \u0026rsquo;table\u0026rsquo; %} {% elif block.block_type == \u0026lsquo;heading\u0026rsquo; %} {% elif block.block_type == \u0026lsquo;publication\u0026rsquo; %} {% else %} {% endif %} {% endfor %}\nStep 9: Restart Server Restart your development server to see the changes:\nbash Copy code python manage.py runserver Now you should be able to add and edit the fixed table content in the Django admin and see it rendered on your blog_page.html. Adjust the styles and templates according to your design preferences.\nThis guide assumes a basic project structure, so adjust the paths if your project structure is different. Let me know if you have any questions or if there\u0026rsquo;s anything specific you\u0026rsquo;d like to clarify!\nWAGTAIL Upgrade process We recommend upgrading one feature release at a time, even if your project is several versions behind the current one. This has a number of advantages over skipping directly to the newest release:\nIf anything breaks as a result of the upgrade, you will know which version caused it, and will be able to troubleshoot accordingly;\nDeprecation warnings shown in the console output will notify you of any code changes you need to make before upgrading to the following version;\nSome releases make database schema changes that need to be reflected on your project by running ./manage.py makemigrations - this is liable to fail if too many schema changes happen in one go.\nBefore upgrading to a new feature release:\nCheck your project’s console output for any deprecation warnings, and fix them where necessary;\nCheck the new version’s release notes, and the Compatible Django / Python versions table below, for any dependencies that need upgrading first;\nMake a backup of your database.\nTo upgrade:\nUpdate the wagtail line in your project’s requirements.txt file to specify the latest patch release of the version you wish to install. For example, to upgrade to version 1.8.x, the line should read: `wagtail\u0026gt;=1.8,\u0026lt;1.9 Run:\npip install -r requirements.txt ./manage.py makemigrations ./manage.py migrate`\nMake any necessary code changes as directed in the “Upgrade considerations” section of the release notes.\nTest that your project is working as expected.\nRemember that the JavaScript and CSS files used in the Wagtail admin may have changed between releases - if you encounter erratic behaviour on upgrading, ensure that you have cleared your browser cache. When deploying the upgrade to a production server, be sure to run ./manage.py collectstatic to make the updated static files available to the web server. In production, we recommend enabling ManifestStaticFilesStorage in the STATICFILES_STORAGE setting - this ensures that different versions of files are assigned distinct URLs.\nFEEDING DATA FROM DJANGO TO WAGATAIL VIA API Steps:\nTo create a Django API app and expose the data to your Wagtail project, you can follow these steps:\nStep 1: Create Django API App (create a Django app from 0) Open your terminal and navigate to the root directory of your Django project.\nRun the following command to create a new Django app for your API:\npython manage.py startapp django_api_for_wagtail Install the Django REST framework to use it in your Django API app. Django REST framework is a powerful and flexible toolkit for building Web APIs in Django.\nYou can install it using pip. Open your terminal and navigate to your project\u0026rsquo;s root directory. Then, run the following command:\npip3 install djangorestframework After installing, you\u0026rsquo;ll need to add 'rest_framework' to the INSTALLED_APPS in your project\u0026rsquo;s settings.py:\n# myproject/settings.py INSTALLED_APPS = [ # ... \u0026#39;rest_framework\u0026#39;, # ... ] Now that you have a separate app named django_api_for_wagtail for the purpose, let\u0026rsquo;s create a data input example. Assuming you\u0026rsquo;ve created your Nation model within this app, here are the corrected steps:\nDjango API (Django Side): models.py in django_api_for_wagtail app: # django_api_for_wagtail/models.py from django.db import models class Nation(models.Model): name = models.CharField(max_length=255, unique=True) capital = models.CharField(max_length=255) def __str__(self): return self.name serializers.py in django_api_for_wagtail app: # django_api_for_wagtail/serializers.py from rest_framework import serializers from .models import Nation class NationSerializer(serializers.ModelSerializer): class Meta: model = Nation fields = \u0026#39;__all__\u0026#39; views.py in django_api_for_wagtail app: #django_api_for_wagtail/views.py from rest_framework import generics from .models import Nation from .serializers import NationSerializer class NationAPIView(generics.ListCreateAPIView): queryset = Nation.objects.all() serializer_class = NationSerializer urls.py in django_api_for_wagtail app: # django_api_for_wagtail/urls.py from django.urls import path from .views import NationAPIView urlpatterns = [ path(\u0026#39;nations/\u0026#39;, NationAPIView.as_view(), name=\u0026#39;nation-api\u0026#39;), # Add more URL patterns as needed ] admin.py in django_api_for_wagtail app: Here\u0026rsquo;s an example of how you should register the Nation model in the admin.py file:\n# django_api_for_wagtail/admin.py from django.contrib import admin from .models import Nation @admin.register(Nation) class NationAdmin(admin.ModelAdmin): list_display = (\u0026#39;name\u0026#39;, \u0026#39;capital\u0026#39;) urls.py in progetto_api project: To make Django recognize the URLs of your django_api_for_wagtail app, you need to include the URLs of your app in the urls.py file at the project level. You can do this using Django’s include() function, which allows you to reference other URL configurations.\nHere’s how you might update your urls.py file at the project level:Python\nfrom django.contrib import admin from django.urls import include, path urlpatterns = [ path(\u0026#34;admin/\u0026#34;, admin.site.urls), path(\u0026#34;django_api_for_wagtail/\u0026#34;, include(\u0026#39;django_api_for_wagtail.urls\u0026#39;)), ] Test if the steps are correct python3 manage.py makemigrations python3 manage.py migrate If all is ok you can try:\nhttp://127.0.0.1:8000/django_api_for_wagtail/nations/ (frontend side - with json results)\nhttp://127.0.0.1:8000/admin/django_api_for_wagtail/nation/ (backend side - with admin panel)\nIn this way, I can verify the correct data entry on the backend side and the correct management in JSON on the frontend side.\nStep 2: Create Views for API In the api app directory, create a views.py file.\nDefine a view for your API in views.py. For example:\nfrom rest_framework import generics from blog.models import BlogPage from .serializers import BlogPageSerializer class BlogPageAPIView(generics.ListAPIView): queryset = BlogPage.objects.all() serializer_class = BlogPageSerializer Step 3: Configure URLs for API In the api app directory, create a urls.py file.\nDefine the URL patterns for your API in urls.py. For example:\nfrom django.urls import path from .views import BlogPageAPIView urlpatterns = [ path(\u0026#39;blog/\u0026#39;, BlogPageAPIView.as_view(), name=\u0026#39;blog-api\u0026#39;), # Add more URL patterns as needed ] Step 4: Configure Main Project URLs In the main project directory, open the urls.py file.\nInclude the URLs of your API app in the project\u0026rsquo;s URL configuration. Update the urlpatterns:\nfrom django.contrib import admin from django.urls import path, include urlpatterns = [ path(\u0026#39;admin/\u0026#39;, admin.site.urls), path(\u0026#39;api/\u0026#39;, include(\u0026#39;api.urls\u0026#39;)), # Adjust the URL pattern as needed # Add other URL patterns as needed ] Step 5: Run Migrations and Start the Development Server Run the following commands to apply migrations and start the development server:\nmanage.py makemigrations python manage.py migrate python manage.py runserver Definitive Code for mini Django project API Step 6: create the a frontend (to see the data ) To create a simple frontend to visualize the results from your Django API, you can use Django\u0026rsquo;s built-in templates. Here\u0026rsquo;s a step-by-step guide:\nCreate a templates directory within your django_api_for_wagtail app.\nInside the templates directory, create an HTML file for rendering the nation data. Let\u0026rsquo;s call it nations_list.html.\n\u0026lt;!-- django_api_for_wagtail/templates/nations_list.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Nations List\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Nations List\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; {% for nation in nations %} \u0026lt;li\u0026gt;{{ nation.name }} - {{ nation.capital }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Update your views.py to use this template:\n# django_api_for_wagtail/views.py from django.shortcuts import render from rest_framework import generics from .models import Nation from .serializers import NationSerializer class NationAPIView(generics.ListCreateAPIView): queryset = Nation.objects.all() serializer_class = NationSerializer def list(self, request, *args, **kwargs): nations = self.get_queryset() return render(request, \u0026#39;nations_list.html\u0026#39;, {\u0026#39;nations\u0026#39;: nations}) It is worth to breakdown the code above:\nLet\u0026rsquo;s break down the list method in the NationAPIView class:\n# django_api_for_wagtail/views.py from django.shortcuts import render from rest_framework import generics from .models import Nation from .serializers import NationSerializer class NationAPIView(generics.ListCreateAPIView): queryset = Nation.objects.all() serializer_class = NationSerializer def list(self, request, *args, **kwargs): nations = self.get_queryset() return render(request, \u0026#39;nations_list.html\u0026#39;, {\u0026#39;nations\u0026#39;: nations}) queryset and serializer_class: These are attributes of the NationAPIView class. queryset defines the initial query set of nations, and serializer_class specifies the serializer to be used for serializing the data. list method: This method is part of the ListCreateAPIView class provided by Django REST Framework. It handles the HTTP GET request for the list view. self.get_queryset(): This method retrieves the query set of nations. In this case, it gets all the objects from the Nation model specified in the queryset attribute. render function: This function is used to render an HTML template. It takes the following parameters: request: The HTTP request object. 'nations_list.html': The name of the template file to be rendered. {'nations': nations}: A dictionary containing data to be passed to the template. In this case, it includes the retrieved nations from the query set. return render(...): This line returns the rendered HTML content as an HTTP response. The rendered content will be the result of applying the data from the nations query set to the \u0026rsquo;nations_list.html\u0026rsquo; template. In summary, when a user accesses the URL associated with the NationAPIView, the list method is called. It retrieves the list of nations, passes them to the \u0026rsquo;nations_list.html\u0026rsquo; template, renders the HTML content, and returns it as an HTTP response. This allows you to view a list of nations in a web browser when accessing the corresponding URL.\nLet\u0026rsquo;s break down the list method in more detail:\nlist(self, request, *args, **kwargs): nations = self.get_queryset() return render(request, \u0026#39;nations_list.html\u0026#39;, {\u0026#39;nations\u0026#39;: nations}) self: In Python, self is a convention for referring to the instance of the class. In this context, it represents an instance of the NationAPIView class.\nrequest: This is the HTTP request object that is passed to the view. It contains information about the incoming request, such as the method (GET, POST, etc.), headers, and any data sent in the request.\n\\*args and \\**kwargs: These are used to collect additional positional and keyword arguments. In this case, they are not used in the method body, but the method signature includes them to allow flexibility.The usage of *args and **kwargs provides flexibility when defining functions or methods that can accept a variable number of arguments.\nUsing \\*args for Variable Positional Arguments: example_function(*args): for arg in args: print(arg) example_function(1, 2, 3, \u0026#39;four\u0026#39;) In this example, *args allows the function to accept any number of positional arguments. It collects them into a tuple named args, and the function can iterate over them.\nUsing \\**kwargs for Variable Keyword Arguments:\nexample_function(**kwargs): for key, value in kwargs.items(): print(f\u0026#34;{key}: {value}\u0026#34;) example_function(name=\u0026#39;John\u0026#39;, age=25, city=\u0026#39;New York\u0026#39;) In this example, **kwargs allows the function to accept any number of keyword arguments. It collects them into a dictionary named kwargs, and the function can iterate over the key-value pairs.\nCombining \\*args and \\**kwargs:\nexample_function(arg1, arg2, *args, **kwargs): print(f\u0026#34;arg1: {arg1}\u0026#34;) print(f\u0026#34;arg2: {arg2}\u0026#34;) print(f\u0026#34;Additional positional arguments: {args}\u0026#34;) print(f\u0026#34;Additional keyword arguments: {kwargs}\u0026#34;) example_function(1, 2, 3, 4, key1=\u0026#39;value1\u0026#39;, key2=\u0026#39;value2\u0026#39;) In this example, arg1 and arg2 are regular positional arguments, *args collects additional positional arguments into a tuple, and **kwargs collects additional keyword arguments into a dictionary.\nUsing *args and **kwargs allows a function or method to be more flexible and accommodate a varying number of arguments without explicitly specifying them in the function signature. This is particularly useful in cases where the number of arguments might change or when writing functions that need to work with a wide range of inputs.\nself.get_queryset(): This method is inherited from the ListCreateAPIView class of Django REST Framework. It retrieves the queryset of nations. The get_queryset method is responsible for returning the list of objects that will be used in the view.\nnations: This variable stores the queryset of nations obtained from self.get_queryset().\nrender(request, 'nations_list.html', {'nations': nations}): The render function is a shortcut provided by Django for rendering an HTML template. It takes the following arguments:\nrequest: The HTTP request object. 'nations_list.html': The name of the HTML template file to be rendered. {'nations': nations}: A dictionary containing data to be passed to the template. In this case, it includes the list of nations obtained from the queryset. return render(...): This line returns the rendered HTML content as an HTTP response. The rendered content will be the result of applying the data from the nations queryset to the \u0026rsquo;nations_list.html\u0026rsquo; template. In summary, the list method is responsible for retrieving a queryset of nations and rendering an HTML template (\u0026rsquo;nations_list.html\u0026rsquo;) with the nations\u0026rsquo; data. The rendered HTML content is then returned as an HTTP response. This is a common pattern for providing a list view in a Django REST Framework API.\nUpdate your urls.py to include a URL pattern for rendering the nations list: # django_api_for_wagtail/urls.py from django.urls import path from .views import NationAPIView urlpatterns = [ path(\u0026#39;nations/\u0026#39;, NationAPIView.as_view(), name=\u0026#39;nation-api\u0026#39;), path(\u0026#39;nations/list/\u0026#39;, NationAPIView.as_view(), name=\u0026#39;nations-list\u0026#39;), # Add more URL patterns as needed ] Finally, update your urls.py at the project level to include the django_api_for_wagtail URLs:\n# progetto_api/urls.py from django.contrib import admin from django.urls import path, include urlpatterns = [ path(\u0026#39;admin/\u0026#39;, admin.site.urls), path(\u0026#39;django_api_for_wagtail/\u0026#39;, include(\u0026#39;django_api_for_wagtail.urls\u0026#39;)), ] Now, when you visit the URL http://127.0.0.1:8000/django_api_for_wagtail/nations/list/, it should render the nations list using the template.\nFino a qui\nStep 6: Access the API Open your web browser and navigate to http://127.0.0.1:8000/api/blog/ (or the URL you configured). You should see the serialized data from your Wagtail model. Step 7: Integrate with Wagtail In your Wagtail project, you can now fetch data from the API endpoint (http://127.0.0.1:8000/api/blog/) using Django\u0026rsquo;s requests library or any other method you prefer. Use the retrieved data to populate your Wagtail views/templates as needed. This is a basic setup, and you may need to customize it based on your specific requirements. Additionally, you might want to add authentication and permission controls to secure your API.\nWAGTAIL COMPATIBILITY WITH DJANGO ## - link PYTHON Spiegazione attraverso codice di init, getattribute e super Spesso nei moduli di wagtail si fa riferimento alla classazione e subclassazione. Avere chiri alcuni termini è necessario. Questa è la breve sintesi attraverso un sempio\nclass Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;)` This is a simple class representing a vehicle with a brand. It has an init method that initializes the brand attribute and a start method to print a message when the vehicle starts. Car (inherits from Vehicle):\npython Copy code class Car(Vehicle): def init(self, brand, model): # No use of super() self.model = model\ndef start(self): print(f\u0026quot;{self.brand} {self.model} car started.\u0026quot;) This class represents a specific type of vehicle, a Car, inheriting from the Vehicle class. It has its own init method, but it doesn\u0026rsquo;t use super(), and it has a start method that overrides the start method in the Vehicle class. CarWithSuper (inherits from Car):\nclass CarWithSuper(Car): def init(self, brand, model, color): super().init(brand, model) self.color = color\ndef start(self): super().start() print(f\u0026quot;The {self.color} car is ready to go.\u0026quot;) def __getattribute__(self, name): # Modifying __getattribute__ to add a prefix to the brand attribute if name == \u0026quot;brand\u0026quot;: return \u0026quot;Awesome \u0026quot; + super().__getattribute__(name) else: return super().__getattribute__(name) This class inherits from Car and introduces a new attribute color. It uses super() in the init method to call the init method of the parent class (Car). It overrides the start method, calls the parent\u0026rsquo;s start method using super(), and adds an additional message. It also modifies getattribute to add a prefix (\u0026ldquo;Awesome\u0026rdquo;) to the brand attribute. Examples: Example without super(), init, and getattribute:\ncar_without_super = Car(brand=\u0026quot;Toyota\u0026quot;, model=\u0026quot;Camry\u0026quot;) print(car_without_super.model) # Output: Camry An instance of Car is created without using super(). __init__ in Car is called, but __init__ of the parent (Vehicle) is not called. start method from Vehicle is not available in car_without_super. Example with super(), __init__, and __getattribute__: car_with_super = CarWithSuper(brand=\u0026quot;Ford\u0026quot;, model=\u0026quot;Mustang\u0026quot;, color=\u0026quot;red\u0026quot;) print(car_with_super.brand) # Output: Awesome Ford car_with_super.start() # Output: Ford Mustang car started. The red car is ready to go.\nAn instance of CarWithSuper is created using super() to call init of the parent (Car). getattribute is modified to add a prefix to the brand attribute. start method calls the parent\u0026rsquo;s (Car) start method using super() and adds an additional message. Roles:\ninit: Used for initializing the attributes of an object. In the inheritance chain, it\u0026rsquo;s common to use super().init(\u0026hellip;) to call the initializer of the parent class.\ngetattribute: Called whenever an attribute of an object is accessed. Can be modified to customize attribute access. Used here to modify the behavior of accessing the brand attribute.\nsuper(): Used to refer to the parent class. In init, it\u0026rsquo;s used to call the initializer of the parent class. In methods, it\u0026rsquo;s used to call methods from the parent class. In the provided example, super() helps maintain the hierarchy in inheritance, ensuring that the methods of the parent classes are appropriately called. init is used for object initialization, and getattribute is modified to customize attribute access.\nVediamo ora cosa succede se non utilizziamo i metodi Assenza di init If you don\u0026rsquo;t use the init method in the Vehicle class, the class will still be valid, but instances of the class won\u0026rsquo;t have a constructor to initialize their state. The init method is a special method in Python classes that is automatically called when an object is created. It is used for initializing the attributes of the object.\nHere\u0026rsquo;s what happens when you don\u0026rsquo;t include init:\npython Copy code class Vehicle: def start(self): print(\u0026ldquo;Vehicle started.\u0026rdquo;)\nCreating an instance without init vehicle_instance = Vehicle()\nThis will not raise an error, but the instance won\u0026rsquo;t have a \u0026lsquo;brand\u0026rsquo; attribute. If you try to access \u0026lsquo;brand\u0026rsquo;, it will result in an AttributeError. print(vehicle_instance.start()) # Output: Vehicle started. print(vehicle_instance.brand) # AttributeError: \u0026lsquo;Vehicle\u0026rsquo; object has no attribute \u0026lsquo;brand\u0026rsquo; In the example above, creating an instance of Vehicle without an init method is allowed. However, without an init method, instances won\u0026rsquo;t have any attributes initialized during instantiation. If you try to access an attribute that hasn\u0026rsquo;t been defined, you will get an AttributeError.\nIncluding the init method allows you to initialize the state of an object when it is created. For example:\npython Copy code class Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;) Creating an instance with init vehicle_instance = Vehicle(brand=\u0026ldquo;Toyota\u0026rdquo;)\nNow, the \u0026lsquo;brand\u0026rsquo; attribute is initialized during instantiation. print(vehicle_instance.start()) # Output: Toyota vehicle started. print(vehicle_instance.brand) # Output: Toyota In the second example, the init method is used to initialize the brand attribute when a Vehicle instance is created. This ensures that the instance has a properly initialized state from the beginning.\nEd ora quando posso usare e non usare getattribute?### If you don\u0026rsquo;t define the getattribute method in a class, Python will use the default behavior for attribute access. The default behavior involves looking up the attribute in the object\u0026rsquo;s dictionary and returning its value if found. If the attribute is not found in the object\u0026rsquo;s dictionary, Python looks for the attribute in the class hierarchy.\nHere\u0026rsquo;s what happens if you don\u0026rsquo;t use getattribute:\npython Copy code class Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;) Creating an instance without getattribute vehicle_instance = Vehicle(brand=\u0026ldquo;Toyota\u0026rdquo;)\nAccessing the \u0026lsquo;brand\u0026rsquo; attribute without a custom getattribute print(vehicle_instance.brand) # Output: Toyota\nThe default behavior is used, and there is no need for a custom getattribute in this case. In the example above, we create a Vehicle class with an init method to initialize the brand attribute. When we access the brand attribute, the default attribute access behavior is used, and there is no need for a custom getattribute. The attribute is found in the instance\u0026rsquo;s dictionary, and its value is returned.\nThe getattribute method is a powerful tool for customizing attribute access, and it allows you to intercept attribute access calls and customize the behavior. However, in many cases, you may not need to override it, and the default behavior is sufficient for basic attribute access. Only when you need to customize the attribute access behavior should you consider defining a getattribute method.\nIn the example provided, the getattribute method is used to customize the behavior of accessing the brand attribute in the CarWithSuper class. Specifically, it adds a prefix (\u0026ldquo;Awesome\u0026rdquo;) to the value of the brand attribute before returning it.\nHere\u0026rsquo;s the relevant part of the code:\npython Copy code class CarWithSuper(Car): # \u0026hellip;\ndef __getattribute__(self, name): # Modifying __getattribute__ to add a prefix to the brand attribute if name == \u0026quot;brand\u0026quot;: return \u0026quot;Awesome \u0026quot; + super().__getattribute__(name) else: return super().__getattribute__(name) In this case, the getattribute method is modifying the behavior of accessing the brand attribute. Without this customization, accessing car_with_super.brand would simply return the value of the brand attribute. With the custom getattribute, it returns the value with the added prefix.\nSo, you might need to use getattribute when you want to customize or intercept attribute access calls and modify the behavior based on your specific requirements. It\u0026rsquo;s a powerful tool, but it should be used judiciously, as unnecessary or incorrect use may lead to unexpected behavior and potential issues.\nMIXIN L\u0026rsquo;esempio esposto e che di seguito si ripropone risulta anche un ottimo esempio di mixin\nYes, the provided example with Vehicle, Car, and CarWithSuper can be considered an example of mixin-like behavior. Let me break it down:\nVehicle Class:\npython Copy code class Vehicle: def init(self, brand): self.brand = brand\ndef start(self): print(f\u0026quot;{self.brand} vehicle started.\u0026quot;) This is the base class representing a generic vehicle. It has an init method to initialize the brand attribute and a start method.\nCar Class (Inherits from Vehicle):\npython Copy code class Car(Vehicle): def init(self, brand, model): super().init(brand) self.model = model\ndef start(self): print(f\u0026quot;{self.brand} {self.model} car started.\u0026quot;) The Car class inherits from Vehicle. It has its own init method but uses super() to call the init method of the parent class (Vehicle). It also has its own start method, overriding the start method of Vehicle.\nCarWithSuper Class (Inherits from Car):\npython Copy code class CarWithSuper(Car): def init(self, brand, model, color): super().init(brand, model) self.color = color\ndef start(self): super().start() print(f\u0026quot;The {self.color} car is ready to go.\u0026quot;) def __getattribute__(self, name): if name == \u0026quot;brand\u0026quot;: return \u0026quot;Awesome \u0026quot; + super().__getattribute__('brand') else: return super().__getattribute__(name) The CarWithSuper class inherits from Car and introduces a new attribute (color). It uses super() to call the init method of the parent class (Car). It also overrides the start method, calling the parent\u0026rsquo;s (Car) start method using super() and adding an additional message. Additionally, it modifies getattribute to add a prefix (\u0026ldquo;Awesome\u0026rdquo;) to the brand attribute.\nSo, in this example, the classes are organized in a way that exhibits mixin-like behavior. The CarWithSuper class enhances the behavior of the Car class by adding attributes and modifying methods, and it uses super() to maintain the hierarchy and call methods from parent classes. While it may not strictly adhere to the classic definition of a mixin, it shares some characteristics of mixin-like behavior.\nDefinizione di mixin In object-oriented programming, a mixin is a class that provides a certain functionality to be inherited by a subclass, but is not meant to stand alone. Mixins are used to enhance the functionality of a class without the need for multiple inheritance.\nHere are some key characteristics and features of mixins:\nPurpose-Specific Functionality: Mixins are designed to provide a specific set of functionalities or behaviors that can be easily added to other classes. They encapsulate a piece of behavior.\nReusability: Mixins promote code reuse. Instead of duplicating code in multiple classes, you can create a mixin and include it in various classes that need that particular behavior.\nNo Standalone Use: Mixins are not meant to be instantiated or used independently. They lack the complete implementation to be used as standalone classes. They are intended to be combined with other classes.\nFlexible Composition: Since a class can inherit from multiple mixins, it allows for flexible composition of functionalities. This is in contrast to languages that do not support multiple inheritance directly.\nAvoids Diamond Problem: Mixins can help avoid the \u0026ldquo;diamond problem\u0026rdquo; that arises in languages with multiple inheritance, where a class inherits from two classes that have a common ancestor.\nSmall and Focused: Mixins are typically small and focused on a specific task. This makes them easy to understand, maintain, and reuse.\nSTANDARD COMMANDS IN DJANGO INSTALLATION# python3 -m venv venv USEFUL PROPERTY AND METHOD IN DJANGO L\u0026rsquo;uso di Queryset Django querysets have several notable properties and methods that provide flexibility and ease of use when interacting with the database. Here are some key properties and methods of querysets:\nChaining:\nQuerysets are lazy, meaning they don\u0026rsquo;t hit the database until an action is performed. Multiple filters and operations can be chained together to build complex queries. Example:\npython Copy code queryset = Model.objects.filter(field1=value1).exclude(field2=value2).order_by(\u0026rsquo;-date_created\u0026rsquo;) Slicing:\nQuerysets can be sliced to retrieve a specific range of objects. Example:\npython Copy code queryset = Model.objects.all() result_slice = queryset[5:10] # Retrieve objects 5 through 9 Count:\nThe count method returns the number of objects in the queryset without fetching the actual objects. Example:\npython Copy code count = queryset.count() Distinct:\nThe distinct method eliminates duplicate rows from the queryset. Example:\npython Copy code distinct_values = Model.objects.values(\u0026lsquo;field\u0026rsquo;).distinct() Aggregate:\nThe aggregate method allows for the calculation of aggregate values (e.g., sum, average) on the queryset. Example:\npython Copy code from django.db.models import Avg average_value = Model.objects.aggregate(avg_value=Avg(\u0026rsquo;numeric_field\u0026rsquo;)) Values and ValuesList:\nThe values method returns a queryset of dictionaries representing the values of specific fields. The values_list method returns a queryset of tuples representing the values of specific fields. Example:\npython Copy code values_queryset = Model.objects.values(\u0026lsquo;field1\u0026rsquo;, \u0026lsquo;field2\u0026rsquo;) values_list_queryset = Model.objects.values_list(\u0026lsquo;field1\u0026rsquo;, \u0026lsquo;field2\u0026rsquo;) Exists:\nThe exists method checks if there are any records in the queryset. Example:\nqueryset_exists = Model.objects.filter(field=value).exists() Update and Delete:\nThe update method modifies multiple records in the database without fetching them. The delete method deletes records from the database without fetching them. Example:\npython Copy code Model.objects.filter(field=value).update(status=\u0026lsquo;new_status\u0026rsquo;) Model.objects.filter(field=value).delete() These are just a few of the many properties and methods provided by Django querysets. They offer a powerful and expressive way to interact with the database.\nEsempio in wagtail from datetime import datetime, timedelta, timezone from django.shortcuts import render from wagtail.core.models import Page from your_app.models import RoundPage # Replace \u0026lsquo;your_app\u0026rsquo; with the actual name of your app from path.to.get_deadline_date_for import get_deadline_date_for # Replace \u0026lsquo;path.to\u0026rsquo; with the actual path\ndef docs_internship(request): now = datetime.now(timezone.utc) today = get_deadline_date_for(now) five_weeks_ago = today - timedelta(days=7 * 5)\napplicant_round = RoundPage.objects.filter( pingnew__lte=today, internannounce__gt=today, ).first() intern_round = RoundPage.objects.filter( internannounce__lte=today, internends__gt=five_weeks_ago, ).first() return render(request, 'home/docs/internship_guide.html', { 'applicant_round': applicant_round, 'intern_round': intern_round, }) # Strumenti avanzati: Creare una pagina wagtail all\u0026rsquo;interno di un sito Django (link)[https://docs.wagtail.org/en/latest/advanced_topics/add_to_django_project.html]\nInstallazione in Django al pari livello di manage.py: python3 manage.py startapp blog_wiki_wag\nVerifica in Wagtail di requirements.txt della compatibilità delle versioni tra Django e Wagtail. Nel caso specifico Django\u0026gt;=4.2,\u0026lt;4.3 - wagtail\u0026gt;=5.1,\u0026lt;5.2\nVerifica in Django di requirements.txt: Django==4.2.2\nSe vi è compatibilità in Wagtal: pip3 freeze requriments.txt\n*** Verifica del motore Database in Wagtail in base.py: ***\nDATABASES = { \u0026quot;default\u0026quot;: { \u0026quot;ENGINE\u0026quot;: \u0026quot;django.db.backends.sqlite3\u0026quot;, \u0026quot;NAME\u0026quot;: os.path.join(BASE_DIR, \u0026quot;db.sqlite3\u0026quot;), } }\n*** Verifica del motore database in Django in settings.py: ***\nDATABASES = { 'default': { 'ENGINE': 'django.db.backends.sqlite3', 'NAME': BASE_DIR / 'db.sqlite3', } }\nCome si può vedere sopra i due motori DB sono identici\nOra creare la subdirectory di progetto wagtail che conterrà tutti i file dell\u0026rsquo;app wagtail (quella con il quale si effettuato il requirements.txt)\neffettuare il clone del branch da GB del progetto wagtail (vedere git e github per i dettagli)\na questo punto lanciare il comando Install the Project:\nNavigate to the wagtail-wag directory in your terminal: pip install -r requirements.txt\nAdd Wagtail URLs to Django URLs: path('wagtail/', include('wiki-wag.wagtail_urls')), # nuovo inserimento\nAdd the required wagtail modules in setting.py: `INSTALLED_APPS = [\n\u0026lsquo;wagtail.contrib.forms\u0026rsquo;, \u0026lsquo;wagtail.contrib.redirects\u0026rsquo;, \u0026lsquo;wagtail.embeds\u0026rsquo;, \u0026lsquo;wagtail.sites\u0026rsquo;, \u0026lsquo;wagtail.users\u0026rsquo;, \u0026lsquo;wagtail.snippets\u0026rsquo;, \u0026lsquo;wagtail.documents\u0026rsquo;, \u0026lsquo;wagtail.images\u0026rsquo;, \u0026lsquo;wagtail.search\u0026rsquo;, \u0026lsquo;wagtail.admin\u0026rsquo;,\n\u0026rsquo;taggit\u0026rsquo;, \u0026lsquo;modelcluster\u0026rsquo;,\n\u0026lsquo;django.contrib.admin\u0026rsquo;, \u0026lsquo;django.contrib.auth\u0026rsquo;, \u0026lsquo;django.contrib.contenttypes\u0026rsquo;, \u0026lsquo;django.contrib.sessions\u0026rsquo;, \u0026lsquo;django.contrib.messages\u0026rsquo;, \u0026lsquo;django.contrib.staticfiles\u0026rsquo;, \u0026lsquo;sgq\u0026rsquo;, \u0026lsquo;wagtail\u0026rsquo;, ]`\nAdd\u0026rsquo;wiki-wag\u0026rsquo; app in your Django INSTALLED_APPS as well. Add it if it\u0026rsquo;s not present.\nINSTALLED_APPS = [ # \u0026hellip; \u0026lsquo;wiki-wag\u0026rsquo;, # \u0026hellip; ]\nadd in Django settings this: ` MIDDLEWARE = [ \u0026lsquo;django.contrib.sessions.middleware.SessionMiddleware\u0026rsquo;, \u0026lsquo;django.middleware.common.CommonMiddleware\u0026rsquo;, \u0026lsquo;django.middleware.csrf.CsrfViewMiddleware\u0026rsquo;, \u0026lsquo;django.contrib.auth.middleware.AuthenticationMiddleware\u0026rsquo;, \u0026lsquo;django.contrib.messages.middleware.MessageMiddleware\u0026rsquo;, \u0026lsquo;django.middleware.clickjacking.XFrameOptionsMiddleware\u0026rsquo;, \u0026lsquo;django.middleware.security.SecurityMiddleware\u0026rsquo;,\n\u0026lsquo;wagtail.contrib.redirects.middleware.RedirectMiddleware\u0026rsquo;, ] `\nA questo punto dvrebbe apparire un Warning che indica qualcosa di questo genere :::caution WARNINGS: ?: (wagtailadmin.W003) The WAGTAILADMIN_BASE_URL setting is not defined HINT: This should be the base URL used to access the Wagtail admin site. Without this, URLs in notification emails will not display correctly :::\nProseguire e verificare se in admin panel appaiono gli elementi di inpunt in Admin Panel\nSo now update the urls and run makemirgations and migrate from django.contrib import admin from django.urls import path, include from wagtail import urls as wagtail_urls\nurlpatterns = [ path(\u0026rsquo;\u0026rsquo;, include(\u0026lsquo;sgq.urls\u0026rsquo;)), # Include the app-level URLs path(\u0026lsquo;admin/\u0026rsquo;, admin.site.urls), # path(\u0026lsquo;wagtail/\u0026rsquo;, include(\u0026lsquo;wagtail.core.urls\u0026rsquo;)), # nuovo inserimento path(\u0026lsquo;wagtail/\u0026rsquo;, include(wagtail_urls)), # nuovo inserimento\n]\nDJANGO Create a Django App from 0 (from Create Django API App ) Step 1: Create a Virtual Environment (Optional but recommended) Open your terminal and navigate to the directory where you want to create your Django project. Run the following commands:\npython3 -m venv venv source venv/bin/activate Step 2: Install Django While in the activated virtual environment, install Django using the following command:\npip3 install django Step 3: Create a Django Project\nRun the following command to create a new Django project:\ndjango-admin startproject progetto_api Replace myproject with the desired name for your project.\nStep 4: Navigate to the Project Directory Change into the project directory:\ncd progetto_api Step 5: Create a Django App Run the following command to create a new Django app:\npython3 manage.py startapp django_api_for_wagtail Step 6: Configure Database Open the myproject/settings.py file and configure the app and the database settings. By default, Django uses SQLite for development (if not already configured):\n# myproject/settings.py INSTALLED_APPS = [ # ... \u0026#39;django_api_for_wagtail\u0026#39;, # ... ] # .... # DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.sqlite3\u0026#39;, \u0026#39;NAME\u0026#39;: BASE_DIR / \u0026#34;db.sqlite3\u0026#34;, } } Step 7: Apply Migrations Run the following commands to apply initial migrations:\npython3 manage.py makemigrations python3 manage.py migrate Step 8: Create a Superuser (Optional but recommended) Run the following command to create a superuser account for the Django admin:\nbashCopy code python manage.py createsuperuser Follow the prompts to set a username, email, and password.\nStep 9: Run the Development Server Start the Django development server:\npython3 manage.py runserver Visit http://127.0.0.1:8000/ in your web browser to see the Django welcome page.\nStep 10: Create a Superuser After running the development server return e to your project directory (at manage.py level).\nRun the following command to create a superuser account:\npython3 manage.py createsuperuser Follow the prompts to set a username, email, and password for the superuser account.\nStep 11: Run the Development Server Ensure that the development server is still running:\npython3 manage.py runserver Step 12: Open the Admin Interface Visit http://127.0.0.1:8000/admin/ in your web browser. Log in with the superuser credentials you just created.\nStep 13: Verify Admin Interface Verify that the Django admin interface is working correctly\nStep 14: Initialize a Git Repository Open a new terminal window in your project directory\nThe Git commands to initialize a repository, add files, and make an initial commit should be executed at the root level of your project, where your manage.py file is located. The manage.py file is typically located at the top level of your Django project, not within the virtual environment (venv).\nRun the following commands to initialize a Git repository, add all files, and make an initial commit:\ngit init git add . git commit -m \u0026#34;Initial commit\u0026#34; Step 15: Create a GitHub Repository Go to the GitHub website and log in or create a new account. Click on the \u0026ldquo;+\u0026rdquo; icon in the top right corner and select \u0026ldquo;New repository.\u0026rdquo; Follow the instructions to create a new repository on GitHub. git repo name https://github.com/progettazionemauro/django-api Step 16: Connect Local Repository to GitHub After creating the GitHub repository follow those instructions.\ngit remote add origin https://github.com/progettazionemauro/django-api\ngit branch -M main\nnote: The git branch -M main command is used to rename the current branch. In Git, it\u0026rsquo;s a way to both rename the current branch and force-update the tracking branches.\nHere\u0026rsquo;s what the command does:\ngit branch: This command is used for creating, listing, renaming, and deleting branches in Git. When used without additional options, it lists all the local branches. -M main: This option is used to rename the current branch to \u0026ldquo;main\u0026rdquo;. The -M flag is a shortcut for --move, which is used for renaming branches. When you create a new Git repository or clone an existing one, the default branch is usually named \u0026ldquo;master.\u0026rdquo; However, in recent years, there has been a movement in the Git community to use more inclusive and neutral terminology. As a result, many projects are now using \u0026ldquo;main\u0026rdquo; instead of \u0026ldquo;master\u0026rdquo; as the default branch name.\nThe git branch -M main command is often used after creating a new repository or when transitioning from \u0026ldquo;master\u0026rdquo; to \u0026ldquo;main\u0026rdquo; to update the branch name.\nIt\u0026rsquo;s important to note that if you\u0026rsquo;re renaming the branch you are currently on, you might need to update the remote repository to reflect the new branch name.\ngit remote add origin https://github.com/progettazionemauro/django-api git branch -M main git push -u origin main Make sure to replace \u0026ldquo;your-username\u0026rdquo; and \u0026ldquo;your-repo\u0026rdquo; with your GitHub username and repository name.\nStep 17 bis: problems with git push In doing push it can happen to find issues related to pushing for the first time into Github. For example when you created the repo and added readme.md and it is not present into local repo this can generate a misealignment that che lead to generate an error likse that:\ngit push origin main `To https://github.com/progettazionemauro/django-api` `! [rejected] main -\u0026gt; main (non-fast-forward)` `error: push di alcuni riferimenti su \u0026#39;https://github.com/progettazionemauro/django-api\u0026#39; non riuscito` `suggerimento: Gli aggiornamenti sono stati rifiutati perché l\u0026#39;ultimo commit del branch` `suggerimento: attuale è rimasto indietro rispetto alla sua controparte remota.` `suggerimento: Integra le modifiche remote (ad es. con \u0026#39;git pull ...\u0026#39;) prima di` `suggerimento: eseguire nuovamente il push.` `suggerimento: Vedi la \u0026#39;Nota sui fast forward\u0026#39; in \u0026#39;git push --help\u0026#39; per ulteriori` `suggerimento: dettagli.` So it this is the case the best option if to do this:\nIn alternativa, puoi anche eseguire il comando:git push --force per forzare il push delle tue modifiche, anche se non sono un fast forward. Tuttavia, questa è una soluzione rischiosa perché potrebbe sovrascrivere le modifiche remote che non hai ancora integrato nel tuo branch locale.\nPer capire meglio cosa significa \u0026ldquo;non-fast-forward\u0026rdquo;, è necessario comprendere il concetto di fast forward. Un fast forward è un tipo di push che aggiorna un branch locale con le ultime modifiche apportate a un branch remoto. Il fast forward è possibile solo se le modifiche apportate ai due branch sono consecutive.\nStep 18: Verify GitHub Repository Go to your GitHub repository in the web browser and verify that your code has been pushed successfully.\nThat\u0026rsquo;s it! Now you have a Django project with a superuser account, and your code is version-controlled using Git and hosted on GitHub.\nStep 19: Create Models, Views, and Templates (Optional) You can now start building your Django app by creating models, views, and templates. Define your models in the models.py file, create views in the views.py file, and add templates in the templates directory.\nStep 20: Create API App (Optional) If you want to create a separate app for your API, follow the instructions provided in the previous response to create an api app and set up serializers, views, and URLs.\nThat\u0026rsquo;s it! You now have a basic Django project and app set up. Customize it based on your specific requirements and integrate it with your Wagtail project as needed.\nWorking with Django APP Add new database in the app To create a new model in your Django blog app that holds information about files, images, text, and image links, you can modify your models.py file as follows:\nfrom django.db import models class Post(models.Model): title = models.CharField(max_length=255) text = models.TextField() file_name = models.CharField(max_length=255, unique=True) # Name of the file image_name = models.CharField(max_length=255) # Name of the image image_link = models.URLField() # Link to the image def __str__(self): return self.title In this model:\ntitle: Represents the title of the post. text: Represents the content of the post (text). file_name: Represents the name of the file produced by your autogenerative Python code. image_name: Represents the name of the associated image. image_link: Represents the link to the image. You can adjust the field types and lengths according to your requirements.\nOnce the model is created and migrated, you can register it in the Django admin site to manage it: ```python from django.contrib import admin from .models import Post @admin.register(Post) class PostAdmin(admin.ModelAdmin): list_display = (\u0026#39;title\u0026#39;, \u0026#39;file_name\u0026#39;, \u0026#39;image_name\u0026#39;, \u0026#39;image_link\u0026#39;) After defining the model, don\u0026rsquo;t forget to run the following commands to create and apply the migrations:\npython manage.py makemigrations python manage.py migrate With this setup, you\u0026rsquo;ll be able to add, edit, and delete posts with associated file names, image names, and image links through the Django admin interface. You can also access and manipulate this data programmatically through your Django views and templates as needed.\nStep 21: Create a command to populate Django Admin from /content files directory from Hugo: bash #!/bin/bash Directory containing markdown files markdown_dir=\u0026quot;/home/mauro/Scrivania/dJANGO_apI/progetto_api/sgb_start/content/posts/\u0026rdquo;\nOutput file to store processed file details output_file=\u0026quot;/home/mauro/Scrivania/dJANGO_apI/progetto_api/blog/processed_files.txt\u0026quot;\nCheck if the directory exists if [ ! -d \u0026ldquo;$markdown_dir\u0026rdquo; ]; then\necho \u0026ldquo;Error: Directory $markdown_dir does not exist.\u0026rdquo;\nexit 1\nfi\nCreate or clear the output file \u0026ldquo;$output_file\u0026rdquo;\nIterate over all markdown files in the directory for markdown_file in \u0026ldquo;$markdown_dir\u0026rdquo;/*.md; do\nif [ -f \u0026ldquo;$markdown_file\u0026rdquo; ]; then\nRead contents of the markdown file and escape problematic characters content=$(cat \u0026ldquo;$markdown_file\u0026rdquo; | sed \u0026rsquo;s/\u0026quot;/\\\u0026quot;/g\u0026rsquo; | sed \u0026ldquo;s/\u0026rsquo;/\\\u0026rsquo;/g\u0026rdquo; | tr \u0026lsquo;\\n\u0026rsquo; \u0026rsquo; \u0026lsquo;)\nExtract title from filename filename=$(basename \u0026ndash; \u0026ldquo;$markdown_file\u0026rdquo;)\ntitle=\u0026quot;${filename%.*}\u0026quot;\nConstruct image_link based on the extracted title image_link=\u0026ldquo;http://localhost:1313/posts/${title}/\u0026rdquo;\nPrint the details (for demonstration purposes) echo \u0026ldquo;Title: $title\u0026rdquo;\necho \u0026ldquo;File Name: $filename\u0026rdquo;\necho \u0026ldquo;Content: $content\u0026rdquo;\necho \u0026ldquo;Image Link: $image_link\u0026rdquo;\necho \u0026ldquo;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026rdquo;\nSave the data to the Django database using the Django shell echo \u0026ldquo;from blog.models import Post; Post.objects.create(title=\u0026quot;$title\u0026quot;, text=\u0026quot;$content\u0026quot;, file_name=\u0026quot;$filename\u0026quot;, image_name=\u0026rsquo;\u0026rsquo;, image_link=\u0026quot;$image_link\u0026quot;)\u0026rdquo; | python3 manage.py shell\nLog the details to the output file echo \u0026ldquo;Title: $title\u0026rdquo; \u0026raquo; \u0026ldquo;$output_file\u0026rdquo;\necho \u0026ldquo;File Name: $filename\u0026rdquo; \u0026raquo; \u0026ldquo;$output_file\u0026rdquo;\necho \u0026ldquo;Content: $content\u0026rdquo; \u0026raquo; \u0026ldquo;$output_file\u0026rdquo;\necho \u0026ldquo;Image Link: $image_link\u0026rdquo; \u0026raquo; \u0026ldquo;$output_file\u0026rdquo;\necho \u0026ldquo;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026rdquo; \u0026raquo; \u0026ldquo;$output_file\u0026rdquo;\nelse\necho \u0026ldquo;Error: $markdown_file is not a valid file.\u0026rdquo;\nfi\ndone\necho \u0026ldquo;Processing complete. Details stored in $output_file.\u0026rdquo; In admin.py:\npython from django.contrib import admin\nfrom .models import CustomFeature\nimport os\nimport subprocess\nfrom .models import Post\n@admin.register(CustomFeature)\nclass CustomFeatureAdmin(admin.ModelAdmin):\nlist_display = (\u0026rsquo;name\u0026rsquo;, \u0026lsquo;description\u0026rsquo;)\ndef run_script(self, request, queryset):\ntry:\nThis line retrieves the directory path of the current Python script (admin.py in this case) using file, which is a special attribute in Python that represents the current file path. current_dir = os.path.dirname(file)\nscript_path = os.path.abspath(os.path.join(current_dir, \u0026lsquo;add_page.sh\u0026rsquo;))\nprint(\u0026ldquo;Absolute path to script:\u0026rdquo;, script_path) # Print out the absolute path\nsubprocess.run([script_path], check=True)\nself.message_user(request, \u0026ldquo;Script executed successfully\u0026rdquo;)\nexcept Exception as e:\nself.message_user(request, f\u0026quot;Script execution failed: {e}\u0026quot;, level=\u0026lsquo;ERROR\u0026rsquo;)\nrun_script.short_description = \u0026ldquo;Run add_page.sh\u0026rdquo;\nactions = [run_script]\nfrom .models import Post\n@admin.register(Post)\nclass PostAdmin(admin.ModelAdmin):\nlist_display = (\u0026rsquo;title\u0026rsquo;, \u0026lsquo;file_name\u0026rsquo;, \u0026lsquo;image_name\u0026rsquo;, \u0026lsquo;image_link\u0026rsquo;)\ndef populate_posts(self, request, queryset):\ntry:\ncurrent_dir = os.path.dirname(file)\nscript_path = os.path.abspath(os.path.join(current_dir, \u0026lsquo;populate_posts.sh\u0026rsquo;))\nsubprocess.run([script_path], check=True)\nself.message_user(request, \u0026ldquo;Posts populated successfully\u0026rdquo;)\nexcept Exception as e:\nself.message_user(request, f\u0026quot;Failed to populate posts: {e}\u0026quot;, level=\u0026lsquo;ERROR\u0026rsquo;)\npopulate_posts.short_description = \u0026ldquo;Run populate_posts.sh\u0026rdquo;\nactions = [populate_posts] in models.py:\npython from django.db import models Create your models here. Mauro class CustomFeature(models.Model):\nname = models.CharField(max_length=255, unique=True)\ndescription = models.TextField()\ndef str(self):\nreturn self.name\nclass Post(models.Model):\ntitle = models.CharField(max_length=255)\ntext = models.TextField()\nfile_name = models.CharField(max_length=255, unique=True) # Name of the file\nimage_name = models.CharField(max_length=255) # Name of the image\nimage_link = models.URLField() # Link to the image\ndef str(self):\nreturn self.title\nADVANCED BASH COMMANDS \u0026amp; DJANGO Comando per generare pagine in Hugo #!/bin/bash # Define paths posts_dir=\u0026quot;../sgb_start/content/posts\u0026quot; template_file=\u0026quot;./../cheatsheet.md\u0026quot; # Adjust this path to the location of your cheatsheet.md file # Check if the posts directory exists if [ ! -d \u0026quot;$posts_dir\u0026quot; ]; then echo \u0026quot;Error: Hugo posts directory not found!\u0026quot; exit 1 fi # Check if the template file exists if [ ! -f \u0026quot;$template_file\u0026quot; ]; then echo \u0026quot;Error: Template file not found!\u0026quot; exit 1 fi # Define the new file name new_post_file=\u0026quot;$posts_dir/il_mio_secondo_post.md\u0026quot; # Check if the new post file already exists if [ -f \u0026quot;$new_post_file\u0026quot; ]; then echo \u0026quot;Error: il_mio_secondo_post.md already exists!\u0026quot; exit 1 fi # Extract front matter using sed front_matter=$(sed -n '/^\\+\\+\\+/,/^\\+\\+\\+/p' \u0026quot;$posts_dir/il_mio_primo_post.md\u0026quot;) # Check if front matter is empty if [ -z \u0026quot;$front_matter\u0026quot; ]; then echo \u0026quot;Error: Front matter not found in il_mio_primo_post.md\u0026quot; exit 1 fi # Append the front matter to the new post file echo \u0026quot;$front_matter\u0026quot; \u0026gt; \u0026quot;$new_post_file\u0026quot; # Append the content of the template file to the new post file cat \u0026quot;$template_file\u0026quot; \u0026gt;\u0026gt; \u0026quot;$new_post_file\u0026quot; echo \u0026quot;New post created successfully: $new_post_file\u0026quot; Implementazione del comando add_sheet.sh into Django (nella medesima app) Django app: admin.py from django.contrib import admin from .models import Nation, CustomFeature import os import subprocess @admin.register(Nation) class NationAdmin(admin.ModelAdmin): list_display = ('name', 'capital') @admin.register(CustomFeature) class CustomFeatureAdmin(admin.ModelAdmin): list_display = ('name', 'description') def run_script(self, request, queryset): try: # This line retrieves the directory path of the current Python script (admin.py in this case) using __file__, # which is a special attribute in Python that represents the current file path. ### Django app: admin.py current_dir = os.path.dirname(__file__) script_path = os.path.abspath(os.path.join(current_dir, 'add_page.sh')) print(\u0026quot;Absolute path to script:\u0026quot;, script_path) # Print out the absolute path subprocess.run([script_path], check=True) self.message_user(request, \u0026quot;Script executed successfully\u0026quot;) except Exception as e: self.message_user(request, f\u0026quot;Script execution failed: {e}\u0026quot;, level='ERROR') run_script.short_description = \u0026quot;Run add_page.sh\u0026quot; actions = [run_script] Django app: models.py from django.db import models class Nation(models.Model): name = models.CharField(max_length=255, unique=True) capital = models.CharField(max_length=255) def __str__(self): return self.name class CustomFeature(models.Model): name = models.CharField(max_length=255, unique=True) description = models.TextField() def __str__(self): return self.name Addendum for test: path.py import os def run_script1(): # Get the directory containing the current script file current_dir = os.path.dirname(__file__) # Construct the full path to the script script_path = os.path.abspath(os.path.join(current_dir, '..', '..', 'progetto_api', 'add_page.sh')) return script_path def runs_script2(): current_dir = os.path.dirname(__file__) script_path2 = os.path.abspath(os.path.join(current_dir, 'add_page.sh')) return script_path2 # Print the output directly in the terminal print(run_script1()) print(runs_script2()) ","permalink":"https://example.org/posts/post_number_1/","summary":"Welcome to StackEdit! Ultimo aggiornamento 21/5/24 - h. 17:47 Hi! I\u0026rsquo;m your first Markdown file in StackEdit. If you want to learn about StackEdit, you can read me. If you want to play with Markdown, you can edit me. Once you have finished with me, you can create new files by opening the file explorer on the left corner of the navigation bar.\nFiles StackEdit stores your files in your browser, which means all your files are automatically saved locally and are accessible offline!","title":""},{"content":"Sto verificando la mappa\n","permalink":"https://example.org/about_map/about/","summary":"Sto verificando la mappa","title":"ABOUT"},{"content":"Sto verificando la mappa\n","permalink":"https://example.org/store_locator/about/","summary":"Sto verificando la mappa","title":"ABOUT"},{"content":"","permalink":"https://example.org/posts/search/","summary":"search","title":"Pagina di ricerca"}]